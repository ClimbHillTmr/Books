<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>数据科学入门</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles1.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos402908" class="calibre_"><span class="calibre6"><span class="bold"> 12.1　模型 </span></span></p><p class="calibre_">最近邻法是最简单的预测模型之一，它没有多少数学上的假设，也不要求任何复杂的处理，它所要求的仅仅是：</p><div class="calibre_5"> </div><ul class="calibre_6"><li value="1" class="calibre_7"><p class="calibre_">某种距离的概念</p></li><li value="2" class="calibre_8"><p class="calibre_">一种彼此接近的点具有相似性质的假设</p></li></ul><p class="calibre_">本书中讲到的大部分技术是把数据集看作一个整体，以便学习数据中的模式。相比之下，最近邻法却非常有意地忽略了大量信息，因为对每一个新的数据点进行预测只依赖于少量最接近它的点。</p><p class="calibre_">而且，最近邻法并不能帮助理解你所观察到的任意现象的驱动机制。比如，基于我邻居的投票行为来预测我的投票并不能告诉你我为什么要这样投票，而某些基于（比如说）我的收入和婚姻状况来预测我投票行为的模型很可能会揭示我投票的原因。</p><p class="calibre_">在一般情形中，我们有一些数据和对应的标签集。这些标签可能记作真或假，表示每个输入是否满足诸如“是否是垃圾邮件”“是否有毒”“是否值得观看”这样的条件；或者它们可能表示属性，就像“G、PG、PG-13、R、PG-17”这样的电影评分；或者它们可能是总统候选人的名字；或者它们可能是最受欢迎的编程语言的名称。</p><p class="calibre_">在我们的例子里，数据点是向量，这意味着可以用到第 4 章中的 <tt class="calibre7">distance</tt> 函数。</p><p class="calibre_">比如说我们已选定了数字 <span class="italic">k</span> 的值为 3 或 5，然后想要对某些新的数据点分类时，我们寻找 <span class="italic">k</span> 个已标记的最接近它的点，让这些点在新的输出上投票。</p><p class="calibre_">为此，我们需要一个函数来计算投票结果。一个可能的函数是：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def raw_majority_vote(labels):<br class="calibre12"/>    votes = Counter(labels)<br class="calibre12"/>    winner, _ = votes.most_common(1)[0]<br class="calibre12"/>    return winner<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">但这里没有智能地处理并列的结果。比如，假设我们在对电影评分，且 5 个最接近的电影被评为 G、G、PG、PG 和 R，那么 G 有两票，PG 也有两票。在这种情形下，我们有以下几种选择。</p><div class="calibre_5"> </div><ul class="calibre_6"><li value="1" class="calibre_7"><p class="calibre_">随机选择其中一个获胜者。</p></li><li value="2" class="calibre_8"><p class="calibre_">根据距离加权投票并选择加权的获胜者。</p></li><li value="3" class="calibre_8"><p class="calibre_">减少 <span class="italic">k</span> 值直到找到唯一的获胜者。</p></li></ul><p class="calibre_">我们将运用第三种方法：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def majority_vote(labels):<br class="calibre12"/>    """assumes that labels are ordered from nearest to farthest"""<br class="calibre12"/>    vote_counts = Counter(labels)<br class="calibre12"/>    winner, winner_count = vote_counts.most_common(1)[0]<br class="calibre12"/>    num_winners = len([count<br class="calibre12"/>                       for count in vote_counts.values()<br class="calibre12"/>                       if count == winner_count])<br class="calibre12"/><br class="calibre12"/>    if num_winners == 1:<br class="calibre12"/>        return winner                     # 唯一的获胜者，返回它的值<br class="calibre12"/>    else:<br class="calibre12"/>        return majority_vote(labels[:-1]) # 去掉最远元素，再次尝试<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">这种方法最终是管用的，因为在最坏的情况下，我们会一直减少 <span class="italic">k</span> 值，直到只剩一个标签，此时这个标签就是获胜者。</p><p class="calibre_">使用这个函数很容易创建一个分类器：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def knn_classify(k, labeled_points, new_point):<br class="calibre12"/>    """each labeled point should be a pair (point, label)"""<br class="calibre12"/><br class="calibre12"/>    # 把标记好的点按从最近到最远的顺序排序<br class="calibre12"/>    by_distance = sorted(labeled_points,<br class="calibre12"/>                         key=lambda (point, _): distance(point, new_point))<br class="calibre12"/><br class="calibre12"/>    # 寻找k个最近邻的标签<br class="calibre12"/>    k_nearest_labels = [label for _, label in by_distance[:k]]<br class="calibre12"/><br class="calibre12"/>    # 然后让它们投票<br class="calibre12"/>    return majority_vote(k_nearest_labels)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">让我们看看这是怎么起作用的。</p><div class="mbp_pagebreak" id="calibre_pb_86"></div>
<div class="calibre5">本书由「<a href="https://epubw.com" class="calibre3">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="calibre3">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body></html>

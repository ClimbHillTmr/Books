<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>数据科学入门</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles1.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos478971" class="calibre_"><span class="calibre6"><span class="bold"> 15.8　正则化 </span></span></p><p class="calibre_">在实践中，线性回归经常需要处理具有很多变量的数据集，这时就需要用到另外两个技巧。首先，涉及的变量越多，模型越容易对训练集产生过拟合现象。其次，非零系数越多，越难以搞清楚它们的意义。如果我们的目标是<span class="bold">解释</span> 某些现象，一个只考虑三方面因素的稀疏型模型通常要比涉及数百个因素的模型要更好一些。</p><p class="calibre_">
<span class="bold">正则化</span> 是指给误差项添加一个惩罚项，并且该惩罚项会随着 <tt class="calibre7">beta</tt> 的增大而增大。然后，我们开始设法将误差项和惩罚项的组合值最小化。因此，惩罚项越大，就越能防止系数过大。</p><p class="calibre_">例如，在<span class="bold">岭回归</span> （ridge regression）中，我们添加了一个与 <tt class="calibre7">beta_i</tt> 的平方之和成正比的惩罚项。（当然，我们一般不会惩罚 <tt class="calibre7">beta_0</tt> ，因为它是个常数项。）</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/># alpha是一个*超参数*，用来控制惩罚的程度<br class="calibre12"/># 它有时被叫作"lambda"，但这在Python中另有所指<br class="calibre12"/>def ridge_penalty(beta, alpha):<br class="calibre12"/>  return alpha * dot(beta[1:], beta[1:])<br class="calibre12"/><br class="calibre12"/>def squared_error_ridge(x_i, y_i, beta, alpha):<br class="calibre12"/>    """estimate error plus ridge penalty on beta"""<br class="calibre12"/>    return error(x_i, y_i, beta) ** 2 + ridge_penalty(beta, alpha)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">之后你可以按通常的方法插入梯度下降：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def ridge_penalty_gradient(beta, alpha):<br class="calibre12"/>    """gradient of just the ridge penalty"""<br class="calibre12"/>    return [0] + [2 * alpha * beta_j for beta_j in beta[1:]]<br class="calibre12"/><br class="calibre12"/>def squared_error_ridge_gradient(x_i, y_i, beta, alpha):<br class="calibre12"/>    """the gradient corresponding to the ith squared error term<br class="calibre12"/>    including the ridge penalty"""<br class="calibre12"/>    return vector_add(squared_error_gradient(x_i, y_i, beta),<br class="calibre12"/>                      ridge_penalty_gradient(beta, alpha))<br class="calibre12"/><br class="calibre12"/>def estimate_beta_ridge(x, y, alpha):<br class="calibre12"/>    """use gradient descent to fit a ridge regression<br class="calibre12"/>    with penalty alpha"""<br class="calibre12"/>    beta_initial = [random.random() for x_i in x[0]]<br class="calibre12"/>    return minimize_stochastic(partial(squared_error_ridge, alpha=alpha),<br class="calibre12"/>                               partial(squared_error_ridge_gradient,<br class="calibre12"/>                                       alpha=alpha),<br class="calibre12"/>                               x, y,<br class="calibre12"/>                               beta_initial,<br class="calibre12"/>                               0.001)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">如果令 <tt class="calibre7">alpha</tt> 为 0，则根本不会实施任何惩罚，这时得到的结果跟前面一样：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>random.seed(0)<br class="calibre12"/>beta_0 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.0)<br class="calibre12"/># [30.6, 0.97, -1.87, 0.91]<br class="calibre12"/>dot(beta_0[1:], beta_0[1:]) # 5.26<br class="calibre12"/>multiple_r_squared(x, daily_minutes_good, beta_0) # 0.680<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">随着 <tt class="calibre7">alpha</tt> 的增大，拟合优度会变差，但是 <tt class="calibre7">beta</tt> 会变小：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>beta_0_01 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.01)<br class="calibre12"/># [30.6, 0.97, -1.86, 0.89]<br class="calibre12"/>dot(beta_0_01[1:], beta_0_01[1:])  # 5.19<br class="calibre12"/>multiple_r_squared(x, daily_minutes_good, beta_0_01)  # 0.680<br class="calibre12"/><br class="calibre12"/>beta_0_1 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.1)<br class="calibre12"/># [30.8, 0.95, -1.84, 0.54]<br class="calibre12"/>dot(beta_0_1[1:], beta_0_1[1:])  # 4.60<br class="calibre12"/>multiple_r_squared(x, daily_minutes_good, beta_0_1)  # 0.680<br class="calibre12"/><br class="calibre12"/>beta_1 = estimate_beta_ridge(x, daily_minutes_good, alpha=1)<br class="calibre12"/># [30.7, 0.90, -1.69, 0.085]<br class="calibre12"/>dot(beta_1[1:], beta_1[1:])  # 3.69<br class="calibre12"/>multiple_r_squared(x, daily_minutes_good, beta_1)  # 0.676<br class="calibre12"/><br class="calibre12"/>beta_10 = estimate_beta_ridge(x, daily_minutes_good, alpha=10)<br class="calibre12"/># [28.3, 0.72, -0.91, -0.017]<br class="calibre12"/>dot(beta_10[1:], beta_10[1:])  # 1.36<br class="calibre12"/>multiple_r_squared(x, daily_minutes_good, beta_10)  # 0.573<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">特别地，随着惩罚项的增大，“博士学位”的系数会变成 0，这与我们之前的结果是一致的，即它与 0 没有显著区别。</p><blockquote class="calibre_14"><img src="images/00100.jpg" class="calibre_10"/> 　在利用这个方法之前，通常需要调整数据的规模。因为即使是同一个模型，如果将几年数据一下变为几百年的数据，那么它的最小二乘法系数就会增加上百倍，那样得到的惩罚肯定也会骤增。</blockquote><p class="calibre_">还有一个方法是 lasso 回归，它用的惩罚方式如下所示：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def lasso_penalty(beta, alpha):<br class="calibre12"/>    return alpha * sum(abs(beta_i) for beta_i in beta[1:])<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">总的说来，岭回归的惩罚项会缩小系数，但是，lasso 的惩罚项却趋向于迫使系数变为 0 值，这使得它更适于学习稀疏模型。令人遗憾的是，它不适用于梯度下降法，这意味着我们将无法从头开始解决这个问题。</p><div class="mbp_pagebreak" id="calibre_pb_109"></div>
<div class="calibre5">本书由「<a href="https://epubw.com" class="calibre3">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="calibre3">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body></html>

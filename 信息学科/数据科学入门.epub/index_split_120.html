<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>数据科学入门</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles1.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos510037" class="calibre_"><span class="calibre6"><span class="bold"> 17.2　熵 </span></span></p><p class="calibre_">为了建立一个决策树，我们需要决定提出哪些问题，以及这些问题的提问顺序。树的每个阶段都存在一些不确定性，其中有些不确定性已经被我们消除，而另一些则依旧存在。当知道该动物的腿不超过五条后，我们就已经排除了它是蝗虫的可能性。但是，这并没有排除它是鸭子的可能性。对于每一个可能的问题，我们都可以根据其答案对剩余的可能性空间做进一步分割。</p><p class="calibre_">理想情况下，我们当然愿意选择那些具有能够给决策树的预测提供更多信息的答案的问题。如果有一个是 / 否问题，并且答案为“是”的时候输出为 <tt class="calibre7">True</tt> ，而答案为“否”的时候输出为 <tt class="calibre7">False</tt> （反之亦然），那么这样的问题自然是我们的首选了。相反，如果一个是 / 否问题的答案无论是啥都不能为预测提供新信息的话，那么它就不是一个好的选择。</p><p class="calibre_">我们用<span class="bold">熵</span> （entropy）这个概念来指代“信息含量”，此外，这个词还常用来表示混乱程度。在这里，我们用它来表示与数据相关的不确定性。</p><p class="calibre_">假设我们有一个数据集 <span class="italic">S</span> ，每个数据元素都标明了所属的类别，即元素属于有限类别 <img src="images/00015.jpg" class="calibre_130"/> 中的一种。如果所有数据点都属于同一类别，那么也就不存在不确定性了，这就属于我们喜闻乐见的低熵情形。如果数据点均匀地分布在各个类别中，那么不确定性就较大，这时我们说具有较大的熵。</p><p class="calibre_">从数学的角度来讲，如果 <span class="italic">p<sub class="calibre17"><small class="calibre9"><span class="calibre18"><span class="italic">i</span></span></small></sub>
</span> 表示 <span class="italic">c<sub class="calibre17"><small class="calibre9"><span class="calibre18"><span class="italic">i</span></span></small></sub>
</span> 类别中的数据所占的比例，那么可以把熵定义为：</p><p class="calibre_12"><img src="images/00047.jpg" class="calibre_131"/>
</p><p class="calibre_">按照通常的约定，0log 0=0。</p><p class="calibre_">对于这个定义，我们不必关心其中的细枝末节，只要明白每一个 <img src="images/00052.jpg" class="calibre_132"/> 项都是非负的，并且当 <span class="italic">p<sub class="calibre17"><small class="calibre9"><span class="calibre18"><span class="italic">i</span></span></small></sub>
</span> 接近 0 或 1 时，熵的值也接近 0（如同图 17-2 所示）即可。</p><p class="calibre_12"><img src="images/00062.jpg" class="calibre_133"/>
</p><p class="calibre_">
<span class="bold">图 17-2：-</span><span class="italic"><span class="bold">p</span></span><span class="bold"> log </span><span class="italic"><span class="bold">p</span></span><span class="bold"> 的图像</span>
</p><p class="calibre_">这就意味着，当每一个 <span class="italic">p<sub class="calibre17"><small class="calibre9"><span class="calibre18"><span class="italic">i</span></span></small></sub>
</span> 越接近 0 或 1 时（即当大部分数据都属于同一个类别时），熵就越小；当许多 <span class="italic">p<sub class="calibre17"><small class="calibre9"><span class="calibre18"><span class="italic">i</span></span></small></sub>
</span> 不接近 0 时（即当数据广泛分布于众多类别中时），熵就越大。这正是我们所期望的特性。</p><p class="calibre_">我们可以轻而易举地将上面的定义编写为一个函数：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def entropy(class_probabilities):<br class="calibre12"/>    """given a list of class probabilities, compute the entropy"""<br class="calibre12"/>    return sum(-p * math.log(p, 2)<br class="calibre12"/>               for p in class_probabilities<br class="calibre12"/>               if p)                         # 忽略零可能性<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">我们的数据点是由一对 <tt class="calibre7">(input, label)</tt> 组成的，这就意味着类别概率需要我们自己来计算。需要注意的是，我们并不关心标签与概率之间的关联，我们只在乎概率本身：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def class_probabilities(labels):<br class="calibre12"/>    total_count = len(labels)<br class="calibre12"/>    return [count / total_count<br class="calibre12"/>            for count in Counter(labels).values()]<br class="calibre12"/><br class="calibre12"/>def data_entropy(labeled_data):<br class="calibre12"/>    labels = [label for _, label in labeled_data]<br class="calibre12"/>    probabilities = class_probabilities(labels)<br class="calibre12"/>    return entropy(probabilities)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><div class="mbp_pagebreak" id="calibre_pb_120"></div>
<div class="calibre5">本书由「<a href="https://epubw.com" class="calibre3">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="calibre3">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body></html>

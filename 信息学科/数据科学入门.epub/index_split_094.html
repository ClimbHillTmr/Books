<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>数据科学入门</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles1.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos434881" class="calibre_15"><span class="calibre6"><span class="bold"> 13.4　测试模型 </span></span></p><p class="calibre_">SpamAssassin 垃圾邮件公共语料库（<a href="https://spamassassin.apache.org/publiccorpus/" class="calibre3">https://spamassassin.apache.org/publiccorpus/</a> ）是一个非常不错（尽管有点老）的数据集。我们将考察其中前缀为 20021010 的文件。在 Windows 系统上，你可能需要用到类似 7-Zip（<a href="http://www.7-zip.org/" class="calibre3">http://www.7-zip.org/</a> ）的压缩软件来解压和提取文件。</p><p class="calibre_">提取数据之后（例如提取到 C:\spam 目录下面），你会看到 3 个文件夹：spam、easy_ham 和 hard_ham。每个文件夹中都存放了许多电子邮件，每封邮件都单独存放于一个文件之中。为简单起见，我们只检测每封邮件的主题行。</p><p class="calibre_">那么，我们应如何识别主题呢？通过观察可以发现，这些文件似乎都是以“Subject：”开头的。因此，我们可以利用下面的代码来识别主题内容：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>import glob, re<br class="calibre12"/><br class="calibre12"/># 把路径修改为你存放文件的那个<br class="calibre12"/>path = r"C:\spam\*\*"<br class="calibre12"/><br class="calibre12"/>data = []<br class="calibre12"/><br class="calibre12"/># glob.glob会返回每一个与通配路径所匹配的文件名<br class="calibre12"/>for fn in glob.glob(path):<br class="calibre12"/>    is_spam = "ham" not in fn<br class="calibre12"/><br class="calibre12"/>    with open(fn,'r') as file:<br class="calibre12"/>        for line in file:<br class="calibre12"/>            if line.startswith("Subject:"):<br class="calibre12"/>                # 移除开头的"Subject: "，保留其余内容<br class="calibre12"/>                subject = re.sub(r"^Subject: ", "", line).strip()<br class="calibre12"/>                data.append((subject, is_spam))<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">好了，现在我们把数据分为训练数据和测试数据，然后开始建立分类器：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>random.seed(0)      # 这样你能得到与我相同的答案<br class="calibre12"/>train_data, test_data = split_data(data, 0.75)<br class="calibre12"/><br class="calibre12"/>classifier = NaiveBayesClassifier()<br class="calibre12"/>classifier.train(train_data)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">然后，我们可以检查一下模型的效果如何：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/># 三个元素 (主题，确实是垃圾邮件，预测为垃圾邮件的概率)<br class="calibre12"/>classified = [(subject, is_spam, classifier.classify(subject))<br class="calibre12"/>              for subject, is_spam in test_data]<br class="calibre12"/><br class="calibre12"/># 假设spam_probability &gt; 0.5对应的是预测为垃圾邮件<br class="calibre12"/># 对(actual is_spam, predicted is_spam)的组合计数<br class="calibre12"/>counts = Counter((is_spam, spam_probability &gt; 0.5)<br class="calibre12"/>                 for _, is_spam, spam_probability in classified)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">结果显示，真阳性（即垃圾邮件被分类为 spam）有 101 例，假阳性（即正常邮件被分类为 spam）有 33 例，真阴性（即正常邮件被分类为 ham）有 704 例，以及假阴性（即垃圾邮件被分类为 ham）有 38 例。也就是说，算法的查准率是 101 / (101 + 33) = 75%，查全率是 101 / (101 + 38) = 73%，对于如此简单的一个模型来说，这样的结果已经不错了。</p><p class="calibre_">由此也引出了一个有趣的问题，到底哪些邮件最容易被错误分类呢？请看下面的代码：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/># 根据spam_probability从最小到最大排序<br class="calibre12"/>classified.sort(key=lambda row: row[2])<br class="calibre12"/><br class="calibre12"/># 非垃圾邮件被预测为垃圾邮件的最高概率<br class="calibre12"/>spammiest_hams = filter(lambda row: not row[1], classified)[-5:]<br class="calibre12"/><br class="calibre12"/># 垃圾邮件被预测为垃圾邮件的最低概率<br class="calibre12"/>hammiest_spams = filter(lambda row: row[1], classified)[:5]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">这两种最容易被误判为垃圾邮件的正常邮件都含有单词 needed（它在垃圾邮件中出现的概率要高 77 倍）、insurance（它在垃圾邮件中出现的概率要高 30 倍）和 important（它在垃圾邮件中出现的概率要高 10 倍）。</p><p class="calibre_">最容易误判为正常邮件的垃圾邮件的标题都太短（“Re: girls”），以至于难以判断；排行第二的容易误判为正常邮件的垃圾邮件是信用卡邀约邮件，因为相关的词大多尚未被收录到训练集中。</p><p class="calibre_">同样，我们也可以看出现哪些词最容易被误判为垃圾邮件，具体代码如下所示：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def p_spam_given_word(word_prob):<br class="calibre12"/>    """uses bayes's theorem to compute p(spam | message contains word)"""<br class="calibre12"/><br class="calibre12"/>    # word_prob是由word_probabilities生成的三元素中的一个<br class="calibre12"/>    word, prob_if_spam, prob_if_not_spam = word_prob<br class="calibre12"/>    return prob_if_spam / (prob_if_spam + prob_if_not_spam)<br class="calibre12"/><br class="calibre12"/>words = sorted(classifier.word_probs, key=p_spam_given_word)<br class="calibre12"/><br class="calibre12"/>spammiest_words = words[-5:]<br class="calibre12"/>hammiest_words = words[:5]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">最容易被判定为垃圾邮件的单词包括 money、systemworks、rates、sale 以及 year，这些似乎都与忽悠人买东西有关。而最容易被判定为正常邮件的单词有 spambayes、users、razor、zzzzteana 和 sadev，其中大部分好像都与阻止垃圾邮件相关，这比较奇怪。</p><p class="calibre_">那么，我们该如何改进性能呢？一个显而易见的方法是设法获取更多的训练数据。此外，还有许多可以改善模型本身的方法。大家不妨尝试以下具体的方法。</p><div class="calibre_5"> </div><ul class="calibre_6"><li value="1" class="calibre_7"><p class="calibre_">考察邮件内容，而不是仅仅考察邮件主题。你还必须仔细考虑邮件开头的处理方式。</p></li><li value="2" class="calibre_8"><p class="calibre_">我们的分类器考虑了训练集中包含的所有单词，即使该单词仅仅出现过一次。修改分类器，让它接受一个可选阈值 <tt class="calibre7">min_count</tt> ，并且如果某个单词在训练集中出现次数少于阈值则不予考虑。</p></li><li value="3" class="calibre_8"><p class="calibre_">标记赋予器缺乏相似词（例如 cheap 和 cheapest）的概念。修改分类器，使其接受一个可选的词干分析器（<tt class="calibre7">stemmer</tt> ）函数来找出单词对应的同类词。下面我们以一个非常简单的词干分析器函数为例进行介绍：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def drop_final_s(word):<br class="calibre12"/>    return re.sub("s$", "", word)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">自己创建一个非常好用的词干分析器函数非常困难，所以人们通常使用现成的波特词干器（Porter Stemmer，<a href="http://tartarus.org/martin/PorterStemmer/" class="calibre3">http://tartarus.org/martin/PorterStemmer/</a> ）。</p></li><li value="4" class="calibre_8"><p class="calibre_">虽然我们的特征都是采取了“含有单词 <span class="italic">w<sub class="calibre17"><small class="calibre9"><span class="calibre18"><span class="italic">i</span></span></small></sub>
</span> 的邮件”的形式，但这不代表必须采取这种形式。在我们的代码实现中，也可以添加额外的特征，比如“含有一个数字的邮件”。为此，可以创建类似 contains:number 这样的伪标记，然后修改标记赋予器（<tt class="calibre7">tokenizer</tt> ），让它在适当的时候放出这些伪标记。</p></li></ul><div class="mbp_pagebreak" id="calibre_pb_94"></div>
<div class="calibre5">本书由「<a href="https://epubw.com" class="calibre3">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="calibre3">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body></html>

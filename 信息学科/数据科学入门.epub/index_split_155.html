<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>数据科学入门</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles1.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos681984" class="calibre_"><span class="calibre6"><span class="bold"> 22.3　基于用户的协同过滤方法 </span></span></p><p class="calibre_">一种利用用户兴趣的方法是根据这些兴趣找到有<span class="bold">类似</span> 爱好的人，然后再根据这些人的爱好来向你推荐你可能感兴趣的东西。</p><p class="calibre_">为此，我们需要找到一种指标来衡量两个用户之间的相似程度。就这里来说，我们所使用的指标叫作<span class="bold">余弦相似度</span> （cosine similarity）。给定两个向量 <tt class="calibre7">v</tt> 和 <tt class="calibre7">w</tt> ，余弦相似度的定义如下所示：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def cosine_similarity(v, w):<br class="calibre12"/>    return dot(v, w) / math.sqrt(dot(v, v) * dot(w, w))<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">它用来测量 <tt class="calibre7">v</tt> 和 <tt class="calibre7">w</tt> 之间的“角度”。如果 <tt class="calibre7">v</tt> 和 <tt class="calibre7">w</tt> 指向同一个方向，那么分子和分母都相等，所以其余弦相似度等于 1。如果 <tt class="calibre7">v</tt> 和 <tt class="calibre7">w</tt> 指向相反的方向，那么其余弦相似度就等于 -1。如果 <tt class="calibre7">v</tt> 等于 0，那么无论 <tt class="calibre7">w</tt> 是否为 0（反之亦然 )，dot(<tt class="calibre7">v, w</tt> ) 总是等于 0，所以余弦相似度总为 0。</p><p class="calibre_">我们会把这个计算方法应用到由 0 和 1 构成的向量上面，其中每个向量都表示一个用户的某种爱好。如果用户对第 <span class="italic">i</span> 项事物感兴趣的话，则 <tt class="calibre7">v[i]</tt> 取 1，否则为 0。因此，“爱好相似的用户”就意味着“兴趣向量的方向几乎相同的用户”。兴趣完全相同的用户，其相似度为 1。而没有共同兴趣的用户，其相似度为 0。否则的话，其相似度会介于两者之间：该数值越接近 1，表示“越相似”，该数值越接近 0，表示“越不相似”。</p><p class="calibre_">通常来说，从收集已知的兴趣并为其（隐式 ) 指定索引着手是一个不错的主意。为此，我们可以用集合的观点将那些不重复的兴趣收集到一起，然后把它们放到一个列表中，并对其进行排序。这样的话，在这个列表中的第一个兴趣就是兴趣 0，其他以此类推：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>unique_interests = sorted(list({ interest<br class="calibre12"/>                                 for user_interests in users_interests<br class="calibre12"/>                                 for interest in user_interests }))<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">我们将得到一个列表，开头部分如下所示：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>['Big Data',<br class="calibre12"/> 'C++',<br class="calibre12"/> 'Cassandra',<br class="calibre12"/> 'HBase',<br class="calibre12"/> 'Hadoop',<br class="calibre12"/> 'Haskell',<br class="calibre12"/> # …<br class="calibre12"/>]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">接下来，我们要给每个用户生成一个由 0 和 1 组成的“兴趣”向量。为此，我们只需遍历 <tt class="calibre7">unique_interests</tt> 列表，如果用户有某种兴趣，则相应元素置 1，否则置 0：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def make_user_interest_vector(user_interests):<br class="calibre12"/>    """given a list of interests, produce a vector whose ith element is 1<br class="calibre12"/>    if unique_interests[i] is in the list, 0 otherwise"""<br class="calibre12"/>    return [1 if interest in user_interests else 0<br class="calibre12"/>            for interest in unique_interests]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">之后，我们还可以创建用户兴趣矩阵，为此，我们只需将这个函数映射到由用户的兴趣构成的列表的列表上面即可：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>user_interest_matrix = map(make_user_interest_vector, users_interests)<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">现在，如果用户 <tt class="calibre7">i</tt> 对兴趣 <tt class="calibre7">j</tt> 感兴趣，则 <tt class="calibre7">user_interest_matrix[i][j]</tt> 等于 1，否则为 0。</p><p class="calibre_">由于我们的数据集非常小，因此所有用户两两之间的相似性的计算量不是很大：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)<br class="calibre12"/>                      for interest_vector_j in user_interest_matrix]<br class="calibre12"/>                     for interest_vector_i in user_interest_matrix]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">在这之后，<tt class="calibre7">user_similarities[i][j]</tt> 的数值就能够告诉我们用户 <span class="italic">i</span> 和用户 <span class="italic">j</span> 之间的相似度。</p><p class="calibre_">举例来说，<tt class="calibre7">user_similarities[0][9]</tt> 等于 0.57，因为这两个用户都对 Hadoop、Java 和 Big Data 感兴趣。同时，<tt class="calibre7">user_similarities[0][8]</tt> 的值只有 0.19，因为用户 0 和用户 8 只有一个共同的兴趣，即 Big Data。</p><p class="calibre_">就 <tt class="calibre7">user_similarities[i]</tt> 而言，它存放的是用户 <tt class="calibre7">i</tt> 相对于所有用户的相似度。我们可以用它来写一个函数，来找出与给定用户最相似的用户。同时，我们还需要确保这里不包括用户自身以及相似度为 0 的那些用户。下面我们按照相似度从大到小的顺序对结果进行排序：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def most_similar_users_to(user_id):<br class="calibre12"/>    pairs = [(other_user_id, similarity)                       # 查找<br class="calibre12"/>             for other_user_id, similarity in                  # 其他用户<br class="calibre12"/>                enumerate(user_similarities[user_id])          # 非零<br class="calibre12"/>             if user_id != other_user_id and similarity &gt; 0]   # 相似度<br class="calibre12"/><br class="calibre12"/>    return sorted(pairs,                                       # 将其排序<br class="calibre12"/>                  key=lambda (_, similarity): similarity,      # 相似度<br class="calibre12"/>                  reverse=True)                                # 由大到小<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">举例来说，如果我们调用函数 <tt class="calibre7">most_similar_users_to(0)</tt> ，将得到下列输出：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>[(9, 0.5669467095138409),<br class="calibre12"/> (1, 0.3380617018914066),<br class="calibre12"/> (8, 0.1889822365046136),<br class="calibre12"/> (13, 0.1690308509457033),<br class="calibre12"/> (5, 0.1543033499620919)]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">那么，我们该如何利用这个结果向用户推荐新的兴趣呢？对于每种兴趣，我们可以将其他对其感兴趣的用户的用户相似度加起来：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>def user_based_suggestions(user_id, include_current_interests=False):<br class="calibre12"/>    # 将相似度加起来<br class="calibre12"/>    suggestions = defaultdict(float)<br class="calibre12"/>    for other_user_id, similarity in most_similar_users_to(user_id):<br class="calibre12"/>        for interest in users_interests[other_user_id]:<br class="calibre12"/>            suggestions[interest] += similarity<br class="calibre12"/><br class="calibre12"/>    # 将它们转化成已排序的列表<br class="calibre12"/>    suggestions = sorted(suggestions.items(),<br class="calibre12"/>                         key=lambda (_, weight): weight,<br class="calibre12"/>                         reverse=True)<br class="calibre12"/><br class="calibre12"/>    # 并且（有可能）排除已存在的兴趣<br class="calibre12"/>    if include_current_interests:<br class="calibre12"/>        return suggestions<br class="calibre12"/>    else:<br class="calibre12"/>        return [(suggestion, weight)<br class="calibre12"/>                for suggestion, weight in suggestions<br class="calibre12"/>                if suggestion not in users_interests[user_id]]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">如果我们调用 <tt class="calibre7">user_based_suggestions(0)</tt> ，那么在推荐的兴趣中比较靠前的几个为：</p><blockquote class="calibre_14"><span class="calibre11"><tt class="calibre7"><br class="calibre12"/>[('MapReduce', 0.5669467095138409),<br class="calibre12"/> ('MongoDB', 0.50709255283711),<br class="calibre12"/> ('Postgres', 0.50709255283711),<br class="calibre12"/> ('NoSQL', 0.3380617018914066),<br class="calibre12"/> ('neural networks', 0.1889822365046136),<br class="calibre12"/> ('deep learning', 0.1889822365046136),<br class="calibre12"/> ('artificial intelligence', 0.1889822365046136),<br class="calibre12"/> #...<br class="calibre12"/>]<br class="calibre12"/><br class="calibre12"/><br class="calibre12"/><br class="calibre12"/></tt></span></blockquote><p class="calibre_15">这些东西对于自称对“Big Data”和数据库相关的主题感兴趣的人来说，看起来的确是相当不错的建议。（这些权重自身并无意义，它们只是用于进行排序。）</p><p class="calibre_">但是，当兴趣的数量很大的时候，这种方法就玩不转了。还记得第 12 章中介绍的维度灾难吗？在高维向量空间中，绝大多数向量之间都是离得非常远的（因此它们之间的方向也悬殊很大）。也就是说，当兴趣的数量变大时，即使是与给定用户“最相似的用户”，实际上也很可能根本没有相似之处。</p><p class="calibre_">想象一个类似亚马逊这样的网站，在过去几十年中，我已经从它那里购买了数以千计的商品。你可能试图通过购买模式来找出跟我类似的用户，但在这个世界上，除了我自己之外，恐怕没有谁的购买历史看起来更像我了。无论与我“最相似的”顾客是谁，他很可能根本就不像我，因此，如果将他购买的物品推荐给我的话，基本上就注定了这是一个糟糕的建议。</p><div class="mbp_pagebreak" id="calibre_pb_155"></div>
<div class="calibre5">本书由「<a href="https://epubw.com" class="calibre3">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="calibre3">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body></html>

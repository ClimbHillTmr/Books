<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h3 class="p">8.5　使用卷积神经网络对图片分类</h3>
<p class="ziti3">本节练习使用卷积网络对CIFAR数据集进行分类。在前面接触到了MNIST数据集，它是一堆手写图片，CIFAR也是一堆图片，会比MNIST更为复杂。卷积神经网络最擅长的就是图像数据的处理，所以在CIFAR数据集上做图像识别的练习会更有意思。下面就先从CIFAR开始介绍。</p>
<h4 class="p3">8.5.1　CIFAR介绍</h4>
<p class="ziti3">CIFAR由 Alex Krizhevsky、Vinod Nair和Geoffrey Hinton收集而来，起初的数据集共分为10类，分别为飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车，所以CIFAR数据集常以CIFAR-10命名。CIFAR共包含60 000张32×32的彩色图像（包含50 000张训练图片，10 000张测试图片），其中没有任何类型重叠的情况。</p>
<p class="ziti3">因为是彩色图像，所以这个数据集是三通道的，分别是R，G，B 3个通道。后来CIFAR又出了一个分类更多的版本叫CIFAR-100，从名字也可以看出共有100类，将图片分得更细，当然对神经网络图像识别是更大的挑战了。有了这些数据，我们可以把精力全部投在网络优化上。</p>
<p class="ziti3">CIFAR的官网为<a href="http://www.cs.toronto.edu/~kriz/cifar.html" class="pcalibre calibre2">http://www.cs.toronto.edu/~kriz/cifar.html</a>
 ，不同于MNIST数据集，它的数据集是已经打包好的文件（如图8-12所示），分别为Python、MATLIB、二进制bin文件包，以方便不同的程序读取。</p>
<div class="pic"><img alt="" src="Image00138.jpg" class="calibre4"/>
</div>
<p class="middle-img">图8-12　CIFAR数据集</p>
<h4 class="p3">8.5.2　下载CIFAR数据</h4>
<p class="ziti3">与MNIST类似，TensorFlow中同样有一个下载和导入CIFAR数据集的代码文件，不同的是，自从TensorFlow1.0之后，将里面的Models模块分离了出来。下载和导入CIFAR数据集的代码在models里面，所以要先去TensorFlow的GitHub网站将其下载下来。</p>
<p class="ziti3">如果你使用Git，可以直接用下面的命令下载：</p>
<hr class="calibre6"/>
<pre class="ziti5">git clone https://github.com/tensorflow/models.git</pre>
<hr class="calibre6"/>
<p class="ziti3">如果没有使用Git，可直接复制上面的网址，在右下角单击clone or download按钮，在下方在单击Download ZIP按钮下载代码的压缩包，如图8-13所示。</p>
<div class="pic"><img alt="" src="Image00139.jpg" class="calibre4"/>
</div>
<p class="middle-img">图8-13　model代码下载</p>
<p class="ziti3">代码下载后，将其解压，将里面models/tutorials/image/路径下的CIFAR10复制到本地的Python工作区即可。</p>
<p class="ziti3">现在可以在CIFAR10文件夹下新建Python文件，用来下载和导入CIFAR10图片了。与MNIST不同的是，CIFAR数据集代码不是很方便，下载和导入时都需要单独调用，所以本节的例子代码第一个步会有一个独立的代码文件。</p>
<p class="ziti3">将如下代码文件放到cifar10文件夹下（确保import cifar10能找到对应文件），引入CIFAR10，使用函数maybe_download_and_extract即可完成数据的下载和解压。</p>
<p class="ziti3">代码8-4　CIFAR下载</p>
<hr class="calibre6"/>
<pre class="ziti5">import cifar10
cifar10.maybe_download_and_extract()</pre>
<hr class="calibre6"/>
<p class="ziti3">上面的代码会自动将CIFAR10的bin文件ZIP包下载到\tmp\cifar10_data路径下（如果是Windows就是本地磁盘下的这个路径，如D：\tmp\cifar10_data），然后自动解压到\tmp\cifar10_data\cifar-10-batches-bin路径下。</p>
<p class="ziti3">以上这个环节也可以手动下载，然后解压到指定路径里。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 cifar10.py也可以单独运行，但主要功能并不是下载和解压，所以以库的形式引入到代码里，在Anaconda里面不是太友好，运行第二次时会报错，需要重启console才可以。不过好在我们只运行一次，下载并解压后就不需要了。</p>
<p class="ziti3">在两行代码之后，会看到对应路径下生成的相关文件，如图8-14所示。</p>
<p class="ziti3">其中</p>
<p class="ziti4">·batches.meta.txt：标签说明文件。</p>
<p class="ziti4">·data_batch_x.bin：是训练文件，一共有5个，每个10 000条。</p>
<p class="ziti4">·test.batch.bin：10 000条测试文件。</p>
<div class="pic"><img alt="" src="Image00140.jpg" class="calibre4"/>
</div>
<p class="middle-img">图8-14　生成CIFAR文件</p>
<h4 class="p3">8.5.3　实例40：导入并显示CIFAR数据集</h4>
<p class="ziti3">这里通过import cifar10_input来导入CIFAR数据集，cifar10_input.py里定义了这获取数据的函数，具体调用见代码。</p>
<p class="ziti3">代码8-5　CIFAR</p>
<hr class="calibre6"/>
<pre class="ziti5">01 import  cifar10_input
02 import tensorflow as tf
03 import pylab
04 
05 #取数据
06 batch_size = 128
07 data_dir = '/tmp/cifar10_data/cifar-10-batches-bin'
08 images_test, labels_test = cifar10_input.inputs(eval_data = True, data_
dir = data_dir, batch_size = batch_size)</pre>
<hr class="calibre6"/>
<p class="ziti3">cifar10_input.inputs是专门获取数据的函数，返回数据集和对应的标签，但是cifar10_input.inputs函数会将图片裁剪好，由原来的32×32×3，变成了24×24×3。该函数默认是使用测试数据集，如果使用训练数据集，可以将第一个参数传入eval_data=False。</p>
<p class="ziti3">另外，再将batch_size和dir传入，就可以得到dir下面的batch_size个数据了。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 这里所获得的图片并不是原始图片，是经过了两次变换，首先将32×32尺寸裁剪成了24尺寸，然后又进行了一次图片标准化（减去均值像素，并除以像素方差）。这样做的好处是，使所有的输入都在一个有效的数据分布之内，便于特征的分类处理，会使梯度下降算法的收敛更快。</p>
<p class="ziti3">cifar10_input.py中除了对图像进行了一些预处理，还提供了一个读取大数据的方法示例，即使用queue的方法示例。queue是TesonFlow里常用的方法，尤其是在使用大数据样本做训练时。</p>
<p class="ziti3">关于队列方面的内容会在8.5.8节详细介绍。现在我们将cifar10_input.inputs函数得到的内容显示出来。</p>
<p class="ziti3">代码8-5　CIFAR（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">09 sess = tf.InteractiveSession()
10 tf.global_variables_initializer().run()
11 tf.train.start_queue_runners()
12 image_batch, label_batch = sess.run([images_test, labels_test])
13 print("__\n",image_batch[0])
14 print("__\n",label_batch[0])
15 pylab.imshow(image_batch[0])
16 pylab.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">运行上面的代码，主要显示内容如下：（部分内容略去）</p>
<hr class="calibre6"/>
<pre class="ziti5"> [[[1.24836731  0.04940184 -1.49835348]
  [ 1.117571    0.02760247 -1.56375158]
  [ 1.24836731  0.18019807 -1.41115606]
￼  …… 
   [-1.58555102 -0.40838495  0.5943861 ]
  [-1.82534409 -0.58277994  0.46358991]
  [-1.56375158 -0.23398998  0.89957732]]]
__
 3</pre>
<hr class="calibre6"/>
<p class="ziti3">代码中，session用的是tf.InteractiveSession函数，原因在后面讲队列时会讲，又额外使用了一个train.start_queue_ runners函数，是运行队列的意思。上面代码的输出是图片像素数据和标签数据。可以看到，读取的数据都是进过标准化处理的（变成了均值为0，方差为1的数据分布），所以输出的图片就是乱的（如图8-15所示）。</p>
<div class="pic"><img alt="" src="Image00141.jpg" class="calibre4"/>
</div>
<p class="middle-img">图8-15　CIFAR归一化输出</p>
<h4 class="p3">8.5.4　实例41：显示CIFAR数据集的原始图片</h4>
<p class="ziti3">如果希望看到正常的数据怎么办呢？有两种方式：</p>
<p class="ziti4">·修改cifar10_input.py文件，先让它不去标准化。</p>
<p class="ziti4">·手动读取数据并显示。</p>
<p class="ziti3">先来看第一种方式。直接在cifar10_input.py文件里做如下修改：在240行后添加一行代码，并随后将243行代码的内容改为注释。</p>
<hr class="calibre6"/>
<pre class="ziti5">……
float_image = resized_image
  # Subtract off the mean and divide by the variance of the pixels.
  #float_image = tf.image.per_image_standardization(resized_image)</pre>
<hr class="calibre6"/>
<p class="ziti3">再次运行代码“8-5 cifar.py”文件，输出如图8-16所示。</p>
<p class="ziti3">可以看出是一只松鼠，但图片仍然是被裁剪过的尺寸24×24×3。</p>
<p class="ziti3">另一种方式是自己手动编写代码，参见下面的具体内容：</p>
<p class="ziti3">代码8-6　cifar手动读取</p>
<hr class="calibre6"/>
<pre class="ziti5">import numpy as np  
from scipy.misc import imsave  
  
filename = '/tmp/cifar10_data/cifar-10-batches- 
bin/test_batch.bin'  
  
bytestream = open(filename, "rb")  
buf = bytestream.read(10000 * (1 + 32 * 32 * 3))  
bytestream.close()  
  
data = np.frombuffer(buf, dtype=np.uint8)  
data = data.reshape(10000, 1 + 32*32*3)  
labels_images = np.hsplit(data, [1])  
labels = labels_images[0].reshape(10000)  
images = labels_images[1].reshape(10000, 32, 32, 3)  
  
img = np.reshape(images[0], (3, 32, 32)) #导出第一幅图
img = img.transpose(1, 2, 0)  
  
import pylab 
print(labels[0]) 
pylab.imshow(img)
pylab.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">运行上面的代码，显示内容如图8-17所示。</p>
<div class="pic"><img alt="" src="Image00142.jpg" class="calibre4"/>
</div>
<p class="middle-img">图8-16　CIFAR图片输出1</p>
<div class="pic"><img alt="" src="Image00143.jpg" class="calibre4"/>
</div>
<p class="middle-img">图8-17　CIFAR图片输出2</p>
<p class="ziti3">这次得到的是真实的原始图片，尺寸为32×32×3。</p>
<h4 class="p3">8.5.5　cifar10_input的其他功能</h4>
<p class="ziti3">cifar10_input.py文件里还有个功能更强大的数据——distorted_inputs，可以在代码里找到其实现。它是针对train数据的，对train数据进行了变形处理，起到一个数据增广的作用。在数据集比较小、数据量远远不够的情况下，可以对图片进行翻转、随机剪切等操作以增加数据，制造出更加多的样本，提高对图片的利用率。</p>
<p class="ziti3">这部分功能的核心代码在cifar10_input.py文件的第169～183行。具体代码如下：</p>
<hr class="calibre6"/>
<pre class="ziti5"># Randomly crop a [height, width] section of the image.
  distorted_image = tf.random_crop(reshaped_image, [height, width, 3])
 
  # Randomly flip the image horizontally.
  distorted_image = tf.image.random_flip_left_right(distorted_image)
 
  # Because these operations are not commutative, consider randomizing
  # the order their operation.
  distorted_image = tf.image.random_brightness(distorted_image,
                                               max_delta=63)
  distorted_image = tf.image.random_contrast(distorted_image,
                                             lower=0.2, upper=1.8)
 
  # Subtract off the mean and divide by the variance of the pixels.
  float_image = tf.image.per_image_standardization(distorted_image)</pre>
<hr class="calibre6"/>
<p class="ziti3">上述代码中分别调用了不同的函数对图片进行不同的变换，具体解释如下。</p>
<p class="ziti4">·tf.random_crop：为图片随机裁剪。</p>
<p class="ziti4">·tf.image.random_flip_left_right：随机左右翻转。</p>
<p class="ziti4">·tf.image.random_brightness：随机亮度变化。</p>
<p class="ziti4">·tf.image.random_contrast：随机对比度变化。</p>
<p class="ziti4">·tf.image.per_image_standardization：减去均值像素，并除以像素方差（图片标准化）。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 这些函数都是增加数据的好方法，读者可以积累起来，在自己的训练样本中使用。</p>
<h4 class="p3">8.5.6　在TensorFlow中使用queue</h4>
<p class="ziti3">TensorFlow提供了一个队列机制，通过多线程将读取数据与计算数据分开。因为在处理海量数据集的训练时，无法把数据集一次全部载入到内存中，需要一边从硬盘中读取，一边进行训练计算。</p>
<p class="ziti3">对于建立队列读取文件部分的代码，已经在cifar10_input.py里实现了。因为这部分不是本书的重点，所以不做太多介绍，有兴趣的读者可以看下cifar10_input.py里面的源码。</p>
<p class="ziti3">在这里主要讲解内部机制及如何使用，这里分为以下3个知识点。</p>
<p class="ziti4">
<span class="yanse">1．队列线程启动及挂起机制</span>
</p>
<p class="ziti3">还记得8.5.4节中的例子代码（“8-5 CIFAR.py”），在session里面有这么一句：</p>
<hr class="calibre6"/>
<pre class="ziti5">tf.train.start_queue_runners()</pre>
<hr class="calibre6"/>
<p class="ziti3">可以试着将其注释掉，然后运行一下看下效果——程序不动了，这时处于一个挂起状态，start_queue_runners的作用是启动线程，向队列里面读数据。那么为什么会挂起呢？源于下面的这句代码：</p>
<hr class="calibre6"/>
<pre class="ziti5">image_batch, label_batch = sess.run([images_test, labels_test])</pre>
<hr class="calibre6"/>
<p class="ziti3">这句话的意思是从队列里拿出指定批次的数据。但是队列里没有数据，所以程序进入挂起等待状态。</p>
<p class="ziti4">
<span class="yanse">2．在session内部的退出机制</span>
</p>
<p class="ziti3">接下来可以把代码“8-5 CIFAR.py”文件中的session部分改成with语法，如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">with tf.Session() as sess:
    tf.global_variables_initializer().run()
    tf.train.start_queue_runners()
    image_batch, label_batch = sess.run([images_test, labels_test])
    print("__\n",image_batch[0])
    
    print("__\n",label_batch[0])
    pylab.imshow(image_batch[0])
    pylab.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">再次运行程序，发现虽然程序能够正常运行，但是结束后会报错，输出如下信息：</p>
<hr class="calibre6"/>
<pre class="ziti5">ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled
ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled
ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled
ERROR:tensorflow:Exception in QueueRunner: Session has been closed.
ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled
ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled
ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled
……</pre>
<hr class="calibre6"/>
<p class="ziti3">原因就是带with语法的session是自动关闭的。当运行结束后session自动关闭的同时会把里面所有的操作都关掉，而此时的队列还在等待另一个进程往里写数据，所以就会出现错误。最简单的解决方法就是如代码“8-5 CIFAR.py”文件中的session创建方式，使用sess = tf.InteractiveSession来实现。或者，也可以在原来代码中去掉with语句（将上面代码的第1行改后下面代码的第1行），但后面的操作都要指定属于哪个session（将上一段代码的第1～3行改后下面代码的第1～3行）。改完之后的代码如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">sess = tf.Session()
tf.global_variables_initializer().run(session=sess)
tf.train.start_queue_runners(sess=sess)
image_batch, label_batch = sess.run([images_test, labels_test])
print("__\n",image_batch[0])
 
print("__\n",label_batch[0])
pylab.imshow(image_batch[0])
pylab.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">上面的代码在单例程序中没什么问题，资源会随着程序关闭而整体销毁。但如果在复杂的代码中，需要某个线程自动关闭，而不是依赖进程的结束而销毁，这种情况下需要使用tf.train.Coordinator函数来创建一个协调器，以信号量的方式来协调线程间的关系，完成线程间的同步。</p>
<h4 class="p3">8.5.7　实例42：协调器的用法演示</h4>
<p class="ziti3">下面来看一下协调器的用法。</p>
<p class="ziti3">在本例子中，先建立一个100大小的队列。主线程使用计数器不停地加1，队列线程再把主线程里的计数器放到队列里。当队列为空时，主线程在sess.run（queue.dequeue（））语句位置挂起，当队列线程写入对列中时，主线程的计数器同步开始工作。整个操作都是在使用with语法的session中进行的，由于使用了Coordinator，当session要关闭之前会进行coord.request_stop函数将所有线程关闭，之后才会关闭session。</p>
<p class="ziti3">代码8-7　queue</p>
<hr class="calibre6"/>
<pre class="ziti5">import tensorflow as tf
 
#创建长度为100的队列  
queue = tf.FIFOQueue(100,"float")
 
c = tf.Variable(0.0)              #计数器  
#加1操作 
op = tf.assign_add(c,tf.constant(1.0))  
#操作:将计数器的结果加入队列  
enqueue_op = queue.enqueue(c)  
  
#创建一个队列管理器QueueRunner，用这两个操作向q中添加元素。目前我们只使用一个线程
qr = tf.train.QueueRunner(queue,enqueue_ops=[op,enqueue_op]) 
 
with tf.Session() as sess:  
    sess.run(tf.global_variables_initializer())  
       
    coord = tf.train.Coordinator()  
      
    # 启动入队线程，Coordinator是线程的参数  
    enqueue_threads = qr.create_threads(sess, coord = coord,start=True)
     # 启动入队线程  
      
    # 主线程  
    for i in range(0, 10):  
        print ("-------------------------")  
        print(sess.run(queue.dequeue()))  
      
     
    coord.request_stop()  #通知其他线程关闭 其他所有线程关闭之后，这一函数才能返回</pre>
<hr class="calibre6"/>
<p class="ziti3">运行以上代码，输出如下信息：（可以看到并没有报错）</p>
<hr class="calibre6"/>
<pre class="ziti5">3.0
-------------------------
405.0
-------------------------
410.0
-------------------------
413.0
-------------------------
420.0
-------------------------
475.0
-------------------------
478.0
-------------------------
896.0
-------------------------
902.0
-------------------------
904.0</pre>
<hr class="calibre6"/>
<p class="ziti3">这里还可以使用coord.join（enqueue_threads）指定等待某个进程结束。</p>
<h4 class="p3">8.5.8　实例43：为session中的队列加上协调器</h4>
<p class="ziti3">这里将上例中的coord放到启动队列里即可。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">在with tf.Session函数中加入启动队列，并通过加入coord协调器的方式使session close时同步内部线程一起退出。</p>
<p class="ziti3">修改“8-5cifar”代码如下。</p>
<p class="ziti3">代码8-8　cifar队列协调器（部分代码）</p>
<hr class="calibre6"/>
<pre class="ziti5">with tf.Session() as sess:
    tf.global_variables_initializer().run()
    #定义协调器
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess, coord)
    
    image_batch, label_batch = sess.run([images_test, labels_test])
    print("__\n",image_batch[0])
    
    print("__\n",label_batch[0])
    pylab.imshow(image_batch[0])
    pylab.show()
    coord.request_stop()</pre>
<hr class="calibre6"/>
<h4 class="p3">8.5.9　实例44：建立一个带有全局平均池化层的卷积神经网络</h4>
<p class="ziti3">现在正式开始卷积神经网络的示例。在本示例中，使用了全局平均池化层来代替传统的全连接层，使用了3个卷积层的同卷积操作，滤波器为5×5，每个卷积层后面都会跟个步长为2×2的池化层，滤波器为2×2。2层的卷积加池化后是输出为10个通道的卷积层，然后对这10个feature map进行全局平均池化，得到10个特征，再对这10个特征进行softmax计算，其结果来代表最终分类。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">通过一个带有全局平局池化层的卷积神经网络对CIFAR数据集分类。</p>
<p class="ziti3">具体步骤如下：</p>
<p class="ziti4">
<span class="yanse">1．导入头文件引入数据集</span>
</p>
<p class="ziti3">这步骤与前面的代码相似，还是使用cifar10_input里面的代码，导入这种被切割后的24×24尺寸图片。每次取128个图片进行运算。在“cifar10”文件夹下建立“8-9cifar卷积.py”文件，编写如下代码。</p>
<p class="ziti3">代码8-9　cifar卷积</p>
<hr class="calibre6"/>
<pre class="ziti5">01 import cifar10_input
02 import tensorflow as tf
03 import numpy as np
04 
05 batch_size = 128
06 data_dir = '/tmp/cifar10_data/cifar-10-batches-bin'
07 print("begin")
08 images_train, labels_train = cifar10_input.inputs(eval_data = False,
data_dir = data_dir, batch_size = batch_size)
09 images_test, labels_test = cifar10_input.inputs(eval_data = True, data_
dir = data_dir, batch_size = batch_size)
10 print("begin data")</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse">2．定义网络结构</span>
</p>
<p class="ziti3">对于权重w的定义，统一使用函数truncated_normal来生成标准差为0.1的随机数为其初始化。对于权重b的定义，统一初始化为0.1。</p>
<p class="ziti3">卷积操作的函数中，统一进行同卷积操作，即步长为1，padding='SAME'。</p>
<p class="ziti3">池化层有两个函数：</p>
<p class="ziti4">·一个是放在卷积后面，取最大值的方法，步长为2，padding='SAME'，即将原尺寸的长和宽各除以2。</p>
<p class="ziti4">·另一个是用来放在最后一层，取均值的方法，步长为最终生成的特征尺寸6×6（24×24经过两次池化变成了6×6），filter也为6×6。</p>
<p class="ziti3">倒数第二层是没有最大池化的卷积层，因为共有10类，所以卷积输出的是10个通道，并使其全局平均池化为10个节点。</p>
<p class="ziti3">代码8-9　cifar卷积（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">11 def weight_variable(shape):
12   initial = tf.truncated_normal(shape, stddev=0.1)
13   return tf.Variable(initial)
14 
15 def bias_variable(shape):
16   initial = tf.constant(0.1, shape=shape)
17   return tf.Variable(initial)
18   
19 def conv2d(x, W):
20   return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
21 
22 def max_pool_2x2(x):
23   return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
24                         strides=[1, 2, 2, 1], padding='SAME')  
25                         
26 def avg_pool_6x6(x):
27   return tf.nn.avg_pool(x, ksize=[1, 6, 6, 1],
28                         strides=[1, 6, 6, 1], padding='SAME')
29 
30 #定义占位符
31 x = tf.placeholder(tf.float32, [None, 24,24,3]) # cifar data的shape 24*24*3
32 y = tf.placeholder(tf.float32, [None, 10])  # 0～9 数字分类=&gt; 10 classes
33 
34 W_conv1 = weight_variable([5, 5, 3, 64])
35 b_conv1 = bias_variable([64])
36 
37 x_image = tf.reshape(x, [-1,24,24,3])
38 
39 h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
40 h_pool1 = max_pool_2x2(h_conv1)
41 
42 W_conv2 = weight_variable([5, 5, 64, 64])
43 b_conv2 = bias_variable([64])
44 
45 h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
46 h_pool2 = max_pool_2x2(h_conv2)
47 
48 W_conv3 = weight_variable([5, 5, 64, 10])
49 b_conv3 = bias_variable([10])
50 h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)
51 
52 nt_hpool3=avg_pool_6x6(h_conv3)#10
53 nt_hpool3_flat = tf.reshape(nt_hpool3, [-1, 10])
54 y_conv=tf.nn.softmax(nt_hpool3_flat)
55 
56 cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))
57 
58 train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
59 
60 correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))
61 accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))</pre>
<hr class="calibre6"/>
<p class="ziti3">对于梯度优化算法，还是和多分类问题一样，我们使用AdamOptimizer函数，学习率使用0.0001。</p>
<p class="ziti4">
<span class="yanse">3．运行session进行训练</span>
</p>
<p class="ziti3">启动session，迭代15000次数据集，这里记着要启动队列，同时读出来的label还要转成onehot编码。</p>
<p class="ziti3">代码8-9　cifar卷积（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">62 sess = tf.Session()
63 sess.run(tf.global_variables_initializer())
64 tf.train.start_queue_runners(sess=sess)
65 for i in range(15000):#20000
66   image_batch, label_batch = sess.run([images_train, labels_train])
67   label_b = np.eye(10,dtype=float)[label_batch]  #one hot编码
68   
69   train_step.run(feed_dict={x:image_batch, y: label_b},session=sess)
70   
71   if i%200 == 0:
72     train_accuracy = accuracy.eval(feed_dict={
73         x:image_batch, y: label_b},session=sess)
74     print( "step %d, training accuracy %g"%(i, train_accuracy))
75 </pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse">4．评估结果</span>
</p>
<p class="ziti3">从测试数据集里将数据取出，放到模型里运行，查看模型的正确率。</p>
<p class="ziti3">代码8-9　cifar卷积（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">76 image_batch, label_batch = sess.run([images_test, labels_test])
77 label_b = np.eye(10,dtype=float)[label_batch] #one hot编码
78 print ("finished！ test accuracy %g"%accuracy.eval(feed_dict={
79      x:image_batch, y: label_b},session=sess))</pre>
<hr class="calibre6"/>
<p class="ziti3">运行代码后，输出如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">#begin
#begin data
#step 0, training accuracy 0.15625
#step 200, training accuracy 0.3125
#step 400, training accuracy 0.359375
#step 600, training accuracy 0.3125
#step 800, training accuracy 0.382812
#step 1000, training accuracy 0.273438
……
#step 14400, training accuracy 0.554688
#step 14600, training accuracy 0.601562
#step 14800, training accuracy 0.5625
#finished！ test accuracy 0.632812</pre>
<hr class="calibre6"/>
<p class="ziti3">可以看出，识别效果得到了收敛，正确率在0.6左右，这个正确率不算很高，因为模型相对简单，只是用了两层的卷积操作。接下来还将介绍更多的优化方法来提升准确率。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 例子中对于卷积和池化的使用也表明了一种习惯，一般在卷积过程中都会设为步长为1的same卷积，即大小不变，需要降维时则是全部通过池化来完成的。</p>
<h4 class="p3">8.5.10　练习题</h4>
<p class="ziti3">（1）使用前面所学的知识，试着将MNIST图片集进行分类（见代码“8-10 MNIST卷积.py”文件）。</p>
<hr class="calibre6"/>
<pre class="ziti5">01 def max_pool_with_argmax(net, stride):
02     _, mask = tf.nn.max_pool_with_argmax( net,ksize=[1, stride, stride, 
    1], strides=[1, stride, stride, 1],padding='SAME')
03     mask = tf.stop_gradient(mask)
04     net = tf.nn.max_pool(net, ksize=[1, stride, stride, 1],strides=[1, 
    stride, stride, 1], padding='SAME') 
05     return net, mask</pre>
<hr class="calibre6"/>
<p class="ziti3">（2）将CIFAR卷积分类的例子中最后一层改成全连接网络，试试看会有什么效果（见代码“8-11 Cifar全连接卷积.py”）</p>
<div class="calibre1">本书由「<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body>
</html>

<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h3 class="p">7.4　全连接网络训练中的优化技巧</h3>
<p class="ziti3">随着科研人员在使用神经网络训练时不断的尝试，为我们留下了好多有用的技巧，合理地运用这些技巧可以使自己的模型得到更好的拟合效果。本节就来介绍下全连接网络在训练过程中的一些常用技巧。</p>
<h4 class="p3">7.4.1　实例32：利用异或数据集演示过拟合问题</h4>
<p class="ziti3">全连接网络虽然在拟合问题上比较强大，但太强大的拟合效果也带来了其他的麻烦，这就是过拟合问题。什么是过拟合呢？</p>
<p class="ziti3">首先来看一个例子，这次将原有的4个异或数据扩充成上百个具有异或特征的数据集，通过全连接网络将它们进行分类。具体步骤如下：</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">构建异或数据集模拟样本，再构建一个简单的多层神经网络来拟合其样本特征，观察其出现欠拟合的现象，接着通过增大网络复杂性的方式来优化欠拟合问题，使其出现过拟合现象。</p>
<p class="ziti4">
<span class="yanse">1．构建异或数据集</span>
</p>
<p class="ziti3">参照代码“7-2线性多分类.py”文件中的生成模拟数据代码，调用generate函数生成4类数据，然后将其中的两类数据合并。</p>
<p class="ziti3">代码7-6　异或集的过拟合</p>
<hr class="calibre6"/>
<pre class="ziti5">01  np.random.seed(10)
02  
03  input_dim = 2
04  num_classes =4 
05  X, Y = generate(320,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],True)
06  Y=Y%2
07  
08  xr=[]
09  xb=[]
10  for(l,k) in zip(Y[:],X[:]):
11      if l == 0.0 :
12          xr.append([k[0],k[1]])        
13      else:
14          xb.append([k[0],k[1]])
15  xr =np.array(xr)
16  xb =np.array(xb)      
17  plt.scatter(xr[:,0], xr[:,1], c='r',marker='+')
18  plt.scatter(xb[:,0], xb[:,1], c='b',marker='o')
19  plt.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">运行上面的代码，可以看到数据集的结构如图7-15所示。</p>
<div class="pic"><img alt="" src="Image00117.jpg" class="calibre4"/>
</div>
<p class="middle-img">图7-15　异或数据集输出</p>
<p class="ziti3">可以看到，图7-15中的数据分为两类，其中左下和右上是一类（红色用+表示），左上和右下是另一类（蓝色用·表示）。</p>
<p class="ziti4">
<span class="yanse">2．修改定义网络模型</span>
</p>
<p class="ziti3">这里还沿用代码“7-3异或.py”文件里的代码，不用改动，只需要把原来的异或数据集注释掉即可（代码略）。</p>
<p class="ziti4">
<span class="yanse">3．添加可视化</span>
</p>
<p class="ziti3">这里生成120个点并放到模型里，然后将其在直角坐标系中显示出来。</p>
<p class="ziti3">代码7-6　异或集的过拟合（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">20  xTrain, yTrain = generate(120,num_classes, [[3.0,0],[3.0,3.0],[0,3.0]], 
True)
21  yTrain=yTrain%2
22  xr=[]
23  xb=[]
24  for(l,k) in zip(yTrain[:],xTrain[:]):
25      if l == 0.0 :
26          xr.append([k[0],k[1]])        
27      else:
28          xb.append([k[0],k[1]])
29  xr =np.array(xr)
30  xb =np.array(xb)      
31  plt.scatter(xr[:,0], xr[:,1], c='r',marker='+')
32  plt.scatter(xb[:,0], xb[:,1], c='b',marker='o')
33  yTrain=np.reshape(yTrain,[-1,1])           
34  print ("loss:\n", sess.run(loss, feed_dict={x: xTrain, y: yTrain})) 
35  
36  nb_of_xs = 200
37  xs1 = np.linspace(-1, 8, num=nb_of_xs)
38  xs2 = np.linspace(-1, 8, num=nb_of_xs)
39  xx, yy = np.meshgrid(xs1, xs2) # 创建grid
40  # 初始和填充 classification plane
41  classification_plane = np.zeros((nb_of_xs, nb_of_xs))
42  for i in range(nb_of_xs):
43      for j in range(nb_of_xs):
44          classification_plane[i,j] = sess.run(y_pred, feed_dict={x: 
         [[ xx[i,j], yy[i,j] ]]} )
45          classification_plane[i,j] = int(classification_plane[i,j])
46  
47  # 创建一个color map用来显示每一个格子的分类颜色
48  cmap = ListedColormap([
49          colorConverter.to_rgba('r', alpha=0.30),
50          colorConverter.to_rgba('b', alpha=0.30)])
51  # 图示样本的分类边界
52  plt.contourf(xx, yy, classification_plane, cmap=cmap)
53  plt.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">运行上面的代码，得到如下信息：</p>
<hr class="calibre6"/>
<pre class="ziti5">Step: 0 Current loss: 0.50001
Step: 1000 Current loss: 0.359438
……
Step: 10000 Current loss: 0.204833
Step: 11000 Current loss: 0.204797
Step: 12000 Current loss: 0.204775
Step: 13000 Current loss: 0.204766
Step: 14000 Current loss: 0.204765
Step: 15000 Current loss: 0.204765
Step: 16000 Current loss: 0.204765
Step: 17000 Current loss: 0.204765
Step: 18000 Current loss: 0.204765
Step: 19000 Current loss: 0.204765
loss:
 0.204765</pre>
<hr class="calibre6"/>
<p class="ziti3">可视化后生成的数据集结构如图7-16所示。</p>
<div class="pic"><img alt="" src="Image00118.jpg" class="calibre4"/>
</div>
<p class="middle-img">图7-16　失败模型</p>
<p class="ziti3">可以看到，模型在迭代训练10000次之后停止了梯度，而且loss值约为20%，准确率不高，所可视化的图片也没有将数据完全分开。</p>
<p class="ziti4">
<span class="yanse">4．欠拟合定义</span>
</p>
<p class="ziti3">如图7-16所示的这种效果就叫做欠拟合，即没有完全拟合到想要得到的真实数据情况。</p>
<p class="ziti4">
<span class="yanse">5．修正模型提高拟合度</span>
</p>
<p class="ziti3">欠拟合的原因并不是模型不行，而是我们的学习方法无法更精准地学习到适合的模型参数。模型越薄弱，对训练的要求就越高。但是可以采用增加节点或增加层的方式，让模型具有更高的拟合性，从而降低模型的训练难度。</p>
<p class="ziti3">将隐藏层的节点提高到200，代码如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">n_hidden = 200</pre>
<hr class="calibre6"/>
<p class="ziti3">运行代码后显示如下结果：</p>
<hr class="calibre6"/>
<pre class="ziti5">Step: 0 Current loss: 0.510105
Step: 1000 Current loss: 0.0951028
……
Step: 15000 Current loss: 0.0477655
Step: 16000 Current loss: 0.0463676
Step: 17000 Current loss: 0.0451465
Step: 18000 Current loss: 0.043569
Step: 19000 Current loss: 0.0421998</pre>
<hr class="calibre6"/>
<p class="ziti3">可视化后生成的数据集结构如图7-17所示。</p>
<div class="pic"><img alt="" src="Image00119.jpg" class="calibre4"/>
</div>
<p class="middle-img">图7-17　过拟合</p>
<p class="ziti3">从7-17中可以看到强大的全连接网络，仅仅通过一个隐藏层，使用200个点就可以将数据划分得这么细致。而loss值也在逐渐变小，20000次之后变为0.04。</p>
<p class="ziti4">
<span class="yanse">6．验证过拟合</span>
</p>
<p class="ziti3">那么对于上面的模型好不好呢？我们再取少量的数据（12个）放到模型里验证一下，然后用同样的方式在坐标系中可视化（可视化代码部分同上）。</p>
<p class="ziti3">代码7-6　异或集的过拟合（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">54  xTrain, yTrain = generate(12,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]], 
True)
55  yTrain=yTrain%2
56  xr=[]
57  xb=[]
58  for(l,k) in zip(yTrain[:],xTrain[:]):
59      if l == 0.0 :
60          xr.append([k[0],k[1]])        
61      else:
62          xb.append([k[0],k[1]])
63  xr =np.array(xr)
64  xb =np.array(xb)      
65  plt.scatter(xr[:,0], xr[:,1], c='r',marker='+')
66  plt.scatter(xb[:,0], xb[:,1], c='b',marker='o')
67  yTrain=np.reshape(yTrain,[-1,1])           
68  print ("loss:\n", sess.run(loss, feed_dict={x: xTrain, y: yTrain}))
69  #可视化部分
70  ……       </pre>
<hr class="calibre6"/>
<p class="ziti3">运行上面的代码，生成如下信息：</p>
<hr class="calibre6"/>
<pre class="ziti5">loss:
 0.149396</pre>
<hr class="calibre6"/>
<p class="ziti3">可视化后生成的数据集结构如图7-18所示。</p>
<div class="pic"><img alt="" src="Image00120.jpg" class="calibre4"/>
</div>
<p class="middle-img">图7-18　过拟合验证</p>
<p class="ziti3">由图7-18可以看出，loss飙到了14%，并没有原来训练时那么好（4%），模型还是原来的模型，但是这次却框住了少量的样本。这种现象就是过拟合。它与欠拟合一样都是我们在训练模型中不愿意看到的现象，我们要的是真正的拟合在测试情况下能够表现出训练时的良好效果。</p>
<p class="ziti3">避免过拟合的方法有很多：常用的方法有early stopping、数据集扩增、正则化、dropout等。</p>
<p class="ziti4">·early stopping：在发生过拟合之前提前结束训练。理论上是可以的，但是这个点不好把握。</p>
<p class="ziti4">·数据集扩增（data augmentation）：就是让模型见到更多的情况，可以最大化地满足全样本，但实际应用中对于未来事件的预测却显得鞭长莫及。</p>
<p class="ziti4">·正则化（regularization）：是通过引入范数的概念，增强模型的泛化能力，包括L1、L2（L2 regularization也叫weight decay）。</p>
<p class="ziti4">·dropout：是网络模型中的一种方法，每次训练时舍去一些节点来增强泛化能力。</p>
<p class="ziti3">下面重点介绍一下后两种方法。</p>
<h4 class="p3">7.4.2　正则化</h4>
<p class="ziti3">本节将开始学习正则化技巧。</p>
<p class="ziti4">
<span class="yanse">1．什么是正则化</span>
</p>
<p class="ziti3">所谓的正则化，其实就是在神经网络计算损失值的过程中，在损失后面再加一项。这样损失值所代表的输出与标准结果间的误差就会受到干扰，导致学习参数w和b无法按照目标方向来调整，实现模型无法与样本完全拟合的结果，从而达到防止过拟合的效果。</p>
<p class="ziti3">理解了原理之后，现在就来介绍如何添加这个干扰项。干扰项一定要有这样的特性：</p>
<p class="ziti4">·当欠拟合时，希望它对模型误差的影响越小越好，以便让模型快速拟合实际。</p>
<p class="ziti4">·如果是过拟合时，希望它对模型误差的影响越大越好，以便让模型不要产生过拟合的情况。</p>
<p class="ziti3">由此引入了两个范数L1和L2：</p>
<p class="ziti4">·L1：所有学习参数w的绝对值的和。</p>
<p class="ziti4">·L2：所有学习参数w的平方和然后求平方根。</p>
<p class="ziti3">如果放到损失函数的公式里，会将其变形一下，如式（7-1）和式（7-2）所示，其中式（7-1）为L1，式（7-2）为L2。</p>
<div class="pic"><img alt="" src="Image00121.jpg" class="calibre4"/>
</div>
<div class="pic"><img alt="" src="Image00122.jpg" class="calibre4"/>
</div>
<p class="ziti3">最终的loss为等式左边的结果，less（0）代表真实的loss值，less（0）后面的那一项就代表正则化了，λ为一个可以调节的参数，用来控制正则化对loss的影响。</p>
<p class="ziti3">对于L2，将其乘以1/2是为了反向传播时对其求导正好可以将数据规整。</p>
<p class="ziti4">
<span class="yanse">2．TensorFlow中的正则化</span>
</p>
<p class="ziti3">对于上面的公式，读者了解一下就可以了。因为TensorFlow中已经有封装好的函数可以拿来直接使用。</p>
<p class="ziti3">L2的正则化函数为：</p>
<hr class="calibre6"/>
<pre class="ziti5">tf.nn.l2_loss(t, name=None)</pre>
<hr class="calibre6"/>
<p class="ziti3">L1的正则化函数目前在TensorFlow中没有现成的，可以自己组合为：</p>
<hr class="calibre6"/>
<pre class="ziti5">tf.reduce_sum( tf.abs(w))</pre>
<hr class="calibre6"/>
<h4 class="p3">7.4.3　实例33：通过正则化改善过拟合情况</h4>
<p class="ziti3">了解完过拟合的解决方法后，现在就来给前面的代码“7-6异或集的过拟合.py”文件添加正则化的处理。代码非常简单，只需要在计算损失值时加上loss的正则化，例子中，使用的λ为0.01，添加的是L2_loss，代码如下。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">构建异或数据集模拟样本，使用多层神经网络将其分类，并使用正则化技术来改善过拟合情况。</p>
<p class="ziti3">代码7-7　异或集的L2_loss</p>
<hr class="calibre6"/>
<pre class="ziti5">01 ……
02 reg = 0.01                #l2_loss参数
03 loss=tf.reduce_mean((y_pred-y)**2)+tf.nn.l2_loss(weights['h1'])
*reg+tf.nn.l2_loss(weights['h2'])*reg
04 ……</pre>
<hr class="calibre6"/>
<p class="ziti3">其他的地方都不用动，运行代码，结果如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">Step: 0 Current loss: 0.520193
……
Step: 16000 Current loss: 0.0913737
Step: 17000 Current loss: 0.0913519
Step: 18000 Current loss: 0.0913312
Step: 19000 Current loss: 0.0913115
 
loss:
 0.10637</pre>
<hr class="calibre6"/>
<p class="ziti3">可以看出，虽然训练的loss值增加了一些，变成了0.09，但是模型的测试loss却由0.15降到了0.1，比以前进步了不少。可视化后生成的模型如图7-19所示。</p>
<div class="pic"><img alt="" src="Image00123.jpg" class="calibre4"/>
</div>
<p class="middle-img">图7-19　正则化模型</p>
<p class="ziti3">图7-19中，左边为模型在训练时的结果，右边为测试时的结果。图中的蓝色区域比起前面的例子不再是单独封闭的区间了。</p>
<h4 class="p3">7.4.4　实例34：通过增大数据集改善过拟合</h4>
<p class="ziti3">下面再试试通过增大数据集的方式来改善过拟合情况，这里不再生成一次样本，而是每次循环都生成1000个数据，来看看会发生什么。修改代码如下。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">构建异或数据集模拟样本，使用多层神经网络将其分类，并使用增大数据集的方法来改善过拟合情况。</p>
<p class="ziti3">在循环训练中，在for循环里的sess.run之前添加生成数据的代码，每次取1000个点。</p>
<p class="ziti3">代码7-7　异或集的L2_loss（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">05 for i in range(20000):#生成异或数据集
06 
07     X, Y = generate(1000,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],
    True)
08     Y=Y%2
09     Y=np.reshape(Y,[-1,1])
10   
11     _, loss_val = sess.run([train_step, loss], feed_dict={x: X, y: Y})</pre>
<hr class="calibre6"/>
<p class="ziti3">其他地方都不用动，运行代码，生成如下信息：</p>
<hr class="calibre6"/>
<pre class="ziti5">Step: 0 Current loss: 0.399712
Step: 1000 Current loss: 0.141141
……
Step: 17000 Current loss: 0.0992013
Step: 18000 Current loss: 0.0991972
Step: 19000 Current loss: 0.0991939
loss:
 0.09075</pre>
<hr class="calibre6"/>
<p class="ziti3">这次得到的模型测试值直接降到了0.9，比训练时还低。所生成的模型可视化如图7-20所示。</p>
<div class="pic"><img alt="" src="Image00124.jpg" class="calibre4"/>
</div>
<p class="middle-img">图7-20　增大数据集</p>
<p class="ziti3">如图7-20所示增加数据集之后，发现蓝色区域比之前变得更大了，泛化效果也有了明显的提示。</p>
<h4 class="p3">7.4.5　练习题</h4>
<p class="ziti3">试着使用L1_loss来改善过拟合现象，看看效果。</p>
<h4 class="p3">7.4.6　dropout——训练过程中，将部分神经单元暂时丢弃</h4>
<p class="ziti3">还有一种常用的手段叫做dropout，也是用来防止过拟合的。</p>
<p class="ziti4">
<span class="yanse">1．dropout原理</span>
</p>
<p class="ziti3">还有一种常用的改善过拟合的方法dropout。dropout的意思是，在训练过程中，每次随机选择一部分节点不要去“学习”。</p>
<p class="ziti3">这样做的原理是什么呢？</p>
<p class="ziti3">因为从样本数据的分析来看，数据本身是不可能很纯净的，即任何一个模型不能100%把数据完全分开，在某一类中一定会有一些异常数据，过拟合的问题恰恰是把这些异常数据当成规律来学习了。对于模型来讲，我们希望它能够有一定的“智商”，把异常数据过滤掉，只关心有用的规律数据。</p>
<p class="ziti3">异常数据的特点是，它与主流样本中的规律都不同，但是量非常少，相当于在一个样本中出现的概率比主流数据出现的概率低很多。我们就是利用这个特性，通过在每次模型中忽略一些节点的数据学习，将小概率的异常数据获得学习的机会降低，这样这些异常数据对模型的影响就会更小了。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 由于dropout让一部分节点不去“学习”，所以在增加模型的泛化能力的同时，会使学习速度降低，使模型不太容易“学成”，所以在使用的过程中需要合理地调节到底丢弃多少节点，并不是丢弃的节点越多越好。</p>
<p class="ziti4">
<span class="yanse">2．TensorFlow中的dropout</span>
</p>
<p class="ziti3">在TensorFlow中dropout的函数原型如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">def dropout(x, keep_prob, noise_shape=None, seed=None, name=None)</pre>
<hr class="calibre6"/>
<p class="ziti3">其中的参数意义如下。</p>
<p class="ziti4">·X：输入的模型节点。</p>
<p class="ziti4">·keep_prob：保持率。如果为1，则代表全部进行学习；如果为0.8，则代表丢弃20%的节点，只让80%的节点参与学习。</p>
<p class="ziti4">·noise_shape：代表指定x中，哪些维度可以使用dropout技术。为None时，表示所有维度都使用dropout技术。也可以将某个维度标志为1，来代表该维度使用dropout技术。例如：x的形状为[n，len，w，ch]，使用noise_shape为[n，1，1，ch]，这表明会对x中的第二维度len和第三维度w进行dropout。</p>
<p class="ziti4">·seed：随机选取节点的过程中随机数的种子值。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 dropout改变了神经网络的网络结构，它仅仅是属于训练时的方法，所以一般在进行测试时要将dropout的keep_prob变为1，代表不需要进行丢弃，否则会影响模型的正常输出。</p>
<h4 class="p3">7.4.7　实例35：为异或数据集模型添加dropout</h4>
<p class="ziti3">本例在代码“7-7 异或集的L2_loss.py”文件的基础上进行修改，为了体现效果，把原来的l2_loss去掉（实际过程中可以两个方法一起使用）。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">构建异或数据集模拟样本，使用多层神经网络将其分类，并使用dropout技术来改善过拟合情况。</p>
<p class="ziti3">如下代码，在layer_1后面添加一个dropout层，将dropout的keep_prob设为占位符，这样可以在运行时随时指定keep_prob，在session的run中指定keep_prob为0.6，这意味着每次训练将仅允许0.6的节点参与学习运算。由于学习速度慢了，所以要将学习率调大些，变成0.01，加快训练。</p>
<p class="ziti3">另外，在测试时别忘了一定要将keep_prob调成1。</p>
<p class="ziti3">代码7-8　异或集dropout</p>
<hr class="calibre6"/>
<pre class="ziti5">01 ……
02 learning_rate = 0.01#1e-4
03 ……
04 layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights['h1']), biases
['h1']))
05 
06 keep_prob = tf.placeholder("float")
07 layer_1_drop = tf.nn.dropout(layer_1, keep_prob)
08 
09 #Leaky relus激活函数
10 layer2 =tf.add(tf.matmul(layer_1_drop, weights['h2']),biases['h2'])
11 y_pred = tf.maximum(layer2,0.01*layer2)
12 ……
13 for i in range(20000):
14 
15     X, Y = generate(1000,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],
    True)
16     Y=Y%2
17     Y=np.reshape(Y,[-1,1])
18   
19     _, loss_val = sess.run([train_step, loss], feed_dict={x: X, y: Y,
    keep_prob:0.6})
20     
21     if i % 1000 == 0:
22         print ("Step:", i, "Current loss:", loss_val)
23 ……
24 yTrain=np.reshape(yTrain,[-1,1])           
25 print ("loss:\n", sess.run(loss, feed_dict={x: xTrain, y: yTrain,keep_
prob:1.0}))
26 ……</pre>
<hr class="calibre6"/>
<p class="ziti3">运行代码，输出如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">Step: 0 Current loss: 0.503951
Step: 1000 Current loss: 0.0896698
Step: 2000 Current loss: 0.0923921
Step: 3000 Current loss: 0.0912758
Step: 4000 Current loss: 0.0885499
Step: 5000 Current loss: 0.0899685
Step: 6000 Current loss: 0.0923872
Step: 7000 Current loss: 0.0922362
Step: 8000 Current loss: 0.0920109
Step: 9000 Current loss: 0.0918544
Step: 10000 Current loss: 0.0894592
Step: 11000 Current loss: 0.0899565
Step: 12000 Current loss: 0.0939654
Step: 13000 Current loss: 0.0950037
Step: 14000 Current loss: 0.0922148
Step: 15000 Current loss: 0.0934821
Step: 16000 Current loss: 0.093902
Step: 17000 Current loss: 0.0913219
Step: 18000 Current loss: 0.0939114
Step: 19000 Current loss: 0.0912721
loss:
 0.0604928</pre>
<hr class="calibre6"/>
<p class="ziti3">测试效果很不错！这次的模型测试loss比训练的loss值还要低，而且达到了0.06。这就是dropout的效果。</p>
<h4 class="p3">7.4.8　实例36：基于退化学习率dropout技术来拟合异或数据集</h4>
<p class="ziti3">从上面的结果可以看到，损失值在10000时是0.08，后来又涨到了0.09，尤其在最后几次，出现了抖动的现象，这表明后期的学习率有点大了。读者还记得前面学过的退化学习率吗？下面我们就在上面的例子中添加退化学习率，让开始的学习率很大，后面逐渐变小。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">构建异或数据集模拟样本，使用多层神经网络将其分类，并使用dropout配合退化学习率的技术来改善过拟合情况。</p>
<p class="ziti3">在使用优化器的代码部分添加decaylearning_rate，设置总步数为20000，每执行1000步，学习率衰减0.9，见如下代码。</p>
<p class="ziti3">代码7-8　异或集dropout（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">27 global_step = tf.Variable(0, trainable=False)
28 decaylearning_rate = tf.train.exponential_decay(learning_rate, 
global_step,1000, 0.9)
29 #train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)
30 train_step = tf.train.AdamOptimizer(decaylearning_rate).minimize
(loss,global_step=global_step)</pre>
<hr class="calibre6"/>
<p class="ziti3">运行上面代码，输出如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">Step: 0 Current loss: 0.42503
Step: 1000 Current loss: 0.0930188
Step: 2000 Current loss: 0.0894333
Step: 3000 Current loss: 0.0918793
Step: 4000 Current loss: 0.0913094
Step: 5000 Current loss: 0.0913863
Step: 6000 Current loss: 0.0875175
Step: 7000 Current loss: 0.0903373
Step: 8000 Current loss: 0.0899588
Step: 9000 Current loss: 0.0899196
Step: 10000 Current loss: 0.0901761
Step: 11000 Current loss: 0.0887947
Step: 12000 Current loss: 0.0891289
Step: 13000 Current loss: 0.0883277
Step: 14000 Current loss: 0.0908775
Step: 15000 Current loss: 0.0866709
Step: 16000 Current loss: 0.0907037
Step: 17000 Current loss: 0.0897186
Step: 18000 Current loss: 0.0889717
Step: 19000 Current loss: 0.0901095
loss: 0.0568894</pre>
<hr class="calibre6"/>
<p class="ziti3">可以看到，整个loss的趋势是在减小的，而且loss值变成了0.56，比原来更低了，虽然也有些波动，但那是因为dropout随机时受到了异常数据运算结果的影响。</p>
<p class="ziti3">来看一下最终这次模型的可视化效果，如图7-21所示，红色用+表示，蓝色用·表示。</p>
<div class="pic"><img alt="" src="Image00125.jpg" class="calibre4"/>
</div>
<p class="middle-img">图7-21　dropout+退化学习率</p>
<h4 class="p3">7.4.9　全连接网络的深浅关系</h4>
<p class="ziti3">全连接神经网络是一个通用的近似框架。只要有足够多的神经元，即使只有一层隐藏层的神经网络，利用常用的Sigmoid，reLU等激活函数，就可以无限逼近任何连续函数。</p>
<p class="ziti3">在实际中，如果想使用浅层神经网络来拟合复杂非线性函数，就需要靠增加的神经元个数来实现。神经元过多意味着需要训练的参数过多，这会增加网络的学习难度，并影响网络的泛化能力。因此，在搭建网络结构时，一般倾向于使用更深的模型，来减少网络中所需要神经元的数量，使网络有更好的泛化能力。</p>
<div class="calibre1">本书由「<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body>
</html>

<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h3 class="p">10.5　去噪自编码网络的代码实现</h3>
<p class="ziti3">下面进入实例环节，通过例子来构建一个去噪自编码网络。</p>
<h4 class="p3">10.5.1　实例79：使用去噪自编码网络提取MNIST特征</h4>
<p class="ziti3">本节做一个更简单的自编码模型，让784维只通过一层压缩成256维。与前面例子唯一不同的是，将原始的数据进行一些变换，每个像素点都乘以一个高斯噪声，然后在输出的位置仍然使用原始的输入样本，这样迫使网络在提取特征的同时将噪声去掉。为了防止其过拟合，还需要在其中加入Dropout层。</p>
<p class="ziti3">在这个例子中分为如下几个步骤来编写代码。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">对MNIST集原始输入图片加入噪声，在自编码网络中进行训练，以得到抗干扰更强的特征提取模型。</p>
<p class="ziti4">
<span class="yanse">1．引入头文件，创建网络模型及定义学习参数变量</span>
</p>
<p class="ziti3">代码10-5　去噪声自编码</p>
<hr class="calibre6"/>
<pre class="ziti5">01 import numpy as np
02 import tensorflow as tf
03 import matplotlib.pyplot as plt
04 from tensorflow.examples.tutorials.mnist import input_data
05 
06 mnist = input_data.read_data_sets("/data/", one_hot=True)
07 
08 train_X   = mnist.train.images
09 train_Y = mnist.train.labels
10 test_X    = mnist.test.images
11 test_Y  = mnist.test.labels
12 
13 n_input    = 784 
14 n_hidden_1 = 256 
15  
16 # 占位符
17 x = tf.placeholder("float", [None, n_input])
18 y = tf.placeholder("float", [None, n_input])
19 dropout_keep_prob = tf.placeholder("float")
20 
21 #学习参数
22 weights = {
23     'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),
24     'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_1])),
25     'out': tf.Variable(tf.random_normal([n_hidden_1, n_input]))
26 }
27 biases = {
28     'b1': tf.Variable(tf.zeros([n_hidden_1])),
29     'b2': tf.Variable(tf.zeros([n_hidden_1])),
30     'out': tf.Variable(tf.zeros([n_input]))
31 }
32 
33 # 网络模型
34 def denoise_auto_encoder(_X, _weights, _biases, _keep_prob):
35     layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights['h1']), 
    _biases['b1'])) 
36     layer_1out = tf.nn.dropout(layer_1, _keep_prob) 
37     layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1out, _weights
    ['h2']), _biases['b2'])) 
38     layer_2out = tf.nn.dropout(layer_2, _keep_prob) 
39     return tf.nn.sigmoid(tf.matmul(layer_2out, _weights['out']) + 
    _biases['out'])
40 
41 reconstruction = denoise_auto_encoder(x, weights, biases, dropout_
keep_prob)
42 
43 # COST计算
44 cost = tf.reduce_mean(tf.pow(reconstruction-y, 2))
45 # 优化器
46 optm = tf.train.AdamOptimizer(0.01).minimize(cost)</pre>
<hr class="calibre6"/>
<p class="ziti3">可以看到，在定义学习参数时，加了dropout的学习参数，因为后面要为网络添加dropout层。</p>
<p class="ziti4">
<span class="yanse">2．设置训练参数，开始训练</span>
</p>
<p class="ziti3">这一步还和前面例子一样，重点看下一步的变化。</p>
<p class="ziti3">代码10-5　去噪声自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">47 #训练参数
48 epochs     = 20
49 batch_size = 256
50 disp_step  = 2
51 
52 with tf.Session() as sess:
53     sess.run(tf.global_variables_initializer())
54     print ("开始训练")
55     for epoch in range(epochs):
56         num_batch  = int(mnist.train.num_examples/batch_size)
57         total_cost = 0.
58         for i in range(num_batch):</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse">3．生成噪声数据</span>
</p>
<p class="ziti3">在这里做了添加噪声的操作，每次取出一批次的数据，将输入数据的每一个像素都加上0.3倍的高斯噪声。</p>
<p class="ziti3">代码10-5　去噪声自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">59 batch_xs, batch_ys = mnist.train.next_batch(batch_size)
60             batch_xs_noisy = batch_xs + 0.3*np.random.randn(batch_size, 784)
61             feeds = {x: batch_xs_noisy, y: batch_xs, dropout_keep_prob: 1.}
62             sess.run(optm, feed_dict=feeds)
63             total_cost += sess.run(cost, feed_dict=feeds)
64             
65         # 显示训练日志
66         if epoch % disp_step == 0:
67             print ("Epoch %02d/%02d average cost: %.6f" 
68                    % (epoch, epochs, total_cost/num_batch))
69     print ("完成")<br class="calibre3"/>
</pre>
<hr class="calibre6"/>
<p class="ziti3">执行上面的代码，生成如下信息：</p>
<hr class="calibre6"/>
<pre class="ziti5">开始训练
Epoch 00/20 average cost: 0.097613
Epoch 02/20 average cost: 0.073714
Epoch 04/20 average cost: 0.068687
Epoch 06/20 average cost: 0.065391
Epoch 08/20 average cost: 0.063086
Epoch 10/20 average cost: 0.062062
Epoch 12/20 average cost: 0.061144
Epoch 14/20 average cost: 0.060415
Epoch 16/20 average cost: 0.060192
Epoch 18/20 average cost: 0.059686
完成</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse">4．数据可视化</span>
</p>
<p class="ziti3">接下来是数据可视化部分，接着添加以下代码。</p>
<p class="ziti3">代码10-5　去噪声自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">70     show_num = 10
71     test_noisy = mnist.test.images[:show_num] + 0.3*np.random.randn
    (show_num, 784)
72     encode_decode = sess.run(
73         reconstruction, feed_dict={x: test_noisy, dropout_keep_prob: 1.})
74     f, a = plt.subplots(3, 10, figsize=(10, 3))
75     for i in range(show_num):
76         a[0][i].imshow(np.reshape(test_noisy[i], (28, 28)))
77         a[1][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))
78         a[2][i].matshow(np.reshape(encode_decode[i], (28, 28)), cmap=
        plt.get_cmap('gray'))
79     plt.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">执行上面的代码，生成如图10-8所示图片。</p>
<div class="pic"><img alt="" src="Image00208.jpg" class="calibre4"/>
</div>
<p class="middle-img">图10-8　去噪自编码结果1</p>
<p class="ziti3">第一行图片是加入噪声后的输入，第二行图片是原始的样本（在这里作为标签），最后一行是输出。这里为了让结果看起来明显一些，将输出以灰色的图来显示。可以看出，输出的图片还能看出原来的样子，而且基本上将前面的噪声大部分都过滤掉了。</p>
<p class="ziti4">
<span class="yanse">5．测试鲁棒性</span>
</p>
<p class="ziti3">为了测试模型的鲁棒性，我们换一种噪声方式，然后再生成一个样本测试效果（接着上面的sess）。</p>
<p class="ziti3">代码10-5　去噪声自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">80     randidx   = np.random.randint(test_X.shape[0], size=1)
81     orgvec    = test_X[randidx, :]
82     testvec   = test_X[randidx, :]
83     label     = np.argmax(test_Y[randidx, :], 1)
84     
85     print ("label is %d" % (label)) 
86     # 噪音类型
87     print ("Salt and Pepper Noise")
88     noisyvec = testvec
89     rate     = 0.15
90     noiseidx = np.random.randint(test_X.shape[1]
91                                  , size=int(test_X.shape[1]*rate))
92     noisyvec[0, noiseidx] = 1-noisyvec[0, noiseidx]    
93     outvec   = sess.run(reconstruction, feed_dict={x: noisyvec,
      dropout_keep_prob: 1})
94     outimg   = np.reshape(outvec, (28, 28))
95     
96     # 可视化
97     plt.matshow(np.reshape(orgvec, (28, 28)), cmap=plt.get_cmap('gray'))
98     plt.title("Original Image")
99     plt.colorbar()
100     
101     plt.matshow(np.reshape(noisyvec, (28, 28)), cmap=plt.get_cmap
    ('gray'))
102     plt.title("Input Image")
103     plt.colorbar()
104     
105     plt.matshow(outimg, cmap=plt.get_cmap('gray'))
106     plt.title("Reconstructed Image")
107     plt.colorbar()
108     plt.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">执行上面的代码，会生成如下信息，生成的图片如图10-9所示。</p>
<hr class="calibre6"/>
<pre class="ziti5">label is 9
Salt and Pepper Noise</pre>
<hr class="calibre6"/>
<div class="pic"><img alt="" src="Image00209.jpg" class="calibre4"/>
</div>
<p class="middle-img">图10-9　去噪自编码结果2</p>
<p class="ziti3">可以看出，使用Salt and Pepper噪声对原始图片进行干扰后，仍然可以得到很好的效果。</p>
<h4 class="p3">10.5.2　练习题</h4>
<p class="ziti3">试着将dropout的值改成0.5，看一下模型训练出来的样子，然后再将Salt and Pepper噪声变换后的图片放到模型里，观察输出的图片。想想这是为什么？为什么要在去噪声自编码网络里加入dropout。</p>
<div class="calibre1">本书由「<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body>
</html>

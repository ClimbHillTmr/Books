<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h3 class="p">11.5　TensorFlow中的图片分类模型库——slim</h3>
<p class="ziti3">TensorFlow 1.0之后推出了一个叫slim的库，TF-slim是TensorFlow的一个新的轻量级高级API接口。它类似前面所介绍的TensorFlow.contrib.layers模块，将很多常见的TensorFlow函数进行了二次封装，使代码变得更加简洁，特别适用于构建复杂结构的深度神经网络，它可以用来定义、训练和评估复杂的模型。</p>
<p class="ziti3">同时，在TensorFlow的models模块里又提供了大量用slim写好的网络模型结构代码，以及用该代码训练出的模型检查点文件，可以作为我们的预训练模型来使用。这些模型主要是与图片分类相关，包括ResNet、VGG、Inception-ResNet-v2等。下面就来详细了解下slim。</p>
<h4 class="p3">11.5.1　获取models中的 slim模块代码</h4>
<p class="ziti3">为了能够使用models中的代码，需要先验证下我们的TensorFlow版本是否集成了slim模块，接着再从GitHub上将models代码下载下来，具体操作如下。</p>
<p class="ziti4">
<span class="yanse">1．验证slim库</span>
</p>
<p class="ziti3">在使用slim前，要测试本地的tf.contrib.slim模块是否有效。在命令行中输入如下命令：</p>
<hr class="calibre6"/>
<pre class="ziti5">python -c "import tensorflow.contrib.slim as slim;
eval = slim.evaluation.evaluate_once"</pre>
<hr class="calibre6"/>
<p class="ziti3">如果没有生成任何错误，则表明TF-Slim是可以工作的。</p>
<p class="ziti4">
<span class="yanse">2．下载models模块</span>
</p>
<p class="ziti3">接下来需要安装TF-slim image models library。来到以下网址<a href="https://github.com/tensorflow/%20models/" class="pcalibre calibre2">https://github.com/tensorflow/ models/</a>
 ，可以通过Git 将代码复制下来，也可以手动下载下来（具体操作见8.5.2的详细介绍）。然后解压到本地workspace路径下（就是你自己建立的用来放个人TF代码的路径），通过下面的代码来验证它是否工作。</p>
<hr class="calibre6"/>
<pre class="ziti5">cd $workspace/models/research/slim
python -c "from nets import cifarnet; mynet = cifarnet.cifarnet"</pre>
<hr class="calibre6"/>
<p class="ziti3">将上面的$workspace替换成你的工作路径（如笔者的是d：\python）。运行时如果没有发生任何错误，则表明一切正常。</p>
<h4 class="p3">11.5.2　models中的slim目录结构</h4>
<p class="ziti3">在models下的slim中一共有5个文件夹。</p>
<p class="ziti4">·Datasets：处理数据集相关的代码。</p>
<p class="ziti4">·Deployment：部署。通过创建clone方式实现跨机器的分布训练，可以在多CPU和多GPU上实现运算的同步或异步。</p>
<p class="ziti4">·Nets：该文件夹里放着各种网络模型。</p>
<p class="ziti4">·Preprocessing：适用于各个网络的图片处理函数。</p>
<p class="ziti4">·Scripts：运行网络模型的一些案例脚本，这些脚本只能在支持shell的系统下使用。</p>
<p class="ziti3">在这里重点介绍Datasets、nets和Preprocessing这3个文件夹。</p>
<p class="ziti4">
<span class="yanse">1．Dataset——数据集处理模块</span>
</p>
<p class="ziti3">Dataset里放着常用的图片训练数据集相关的代码。主要支持的数据集主要有cifar10、flowers、mnist、imagenet。</p>
<p class="ziti3">代码文件的名字与数据集相对应，可以使用这些代码下载或获取数据集中的数据。以imagenet为例，可以使用如下函数从网上获取imagenet标签。</p>
<hr class="calibre6"/>
<pre class="ziti5">imagenet.create_readable_names_for_imagenet_labels()</pre>
<hr class="calibre6"/>
<p class="ziti3">上面代码返回的是imagenet中1000个类的分类标签名字（与样本序列对应）。</p>
<p class="ziti4">
<span class="yanse">2．nets模块</span>
</p>
<p class="ziti3">nets文件夹下包含前面介绍的各种网络模型，如图11-8所示。</p>
<div class="pic"><img alt="" src="Image00232.jpg" class="calibre4"/>
</div>
<p class="middle-img">图11-8　nets文件结构</p>
<p class="ziti3">每个网络模型文件都是以自己的名字命名的，而且里面的代码结构框架也大致相同，以inception_resnet_v2为例，如表11-1中列出了比较常用的函数接口。</p>
<p class="middle-img">表11-1　slim中nets的代码框架接口</p>
<div class="pic"><img alt="" src="Image00233.jpg" class="calibre4"/>
</div>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 表11-1中的框架全部是使用slim库代码来实现的，由于与tensorflow.contrib.layers模块的使用方式很相似，这里不再展开介绍，但是建议读者配合前面讲的各个模型的结构再看看其具体在代码中的真实实现，对自己构建高效的模型会有很大帮助。</p>
<p class="ziti4">
<span class="yanse">3．Preprocessing模块</span>
</p>
<p class="ziti3">该模块代码里包含几个图片预处理文件，命名也是按照模型的名字来命名的。slim会把某一类模型常用的预处理函数放到一个文件里，并命名为该类模型相关的名字，而且每个代码文件函数结构也大致相似。例如，调用inception_preprocessing函数中的代码如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">inception_preprocessing.preprocess_image</pre>
<hr class="calibre6"/>
<p class="ziti3">该函数是将传入的图片转化成模型尺寸并归一化处理。</p>
<h4 class="p3">11.5.3　slim中的数据集处理</h4>
<p class="ziti3">slim模块包自带了函数，可以用来下载数据集，也可以对数据集进行转换操作。它可以下载标准的数据集并转换为TensorFlow自带的TFRecord格式，还可以使用TF-slim的data reading和queueing utilities来读取TFRecord格式的数据集。slim所支持的数据集如表11-2所示。</p>
<p class="middle-img">表11-2　slim中集成的数据集</p>
<div class="pic"><img alt="" src="Image00234.jpg" class="calibre4"/>
</div>
<p class="ziti3">
<span class="yanse">1. 将数据转为TFRecord格式</span>
</p>
<p class="ziti3">TFRecord是TensorFlow推荐的数据集格式，与TensorFlow框架结合紧密。在TensorFlow中提供了一系列接口可以访问TFRecord格式。该结构存在的意义主要是为了满足在处理海量样本集时，需要边执行训练边从硬盘上读取数据的需求。将原始文件转化成TFRecord的格式，然后在运行中通过多线程的方式来读取，这样可以减小主线程训练的负担，使整个训练过程变得更高效。</p>
<p class="ziti3">只需要在命令行里输入下列命令，即可将下载数据集并将其转成TFRecord格式：</p>
<hr class="calibre6"/>
<pre class="ziti5">D:\python\research\models\slim&gt;python download_and_convert_data.py--dataset_ name=flowers—dataset_dir=/tmp/data/flowers</pre>
<hr class="calibre6"/>
<p class="ziti3">这里需要指定两个关键点：一个是数据集（例子中的flowers），另一个是下载路径（笔者的Python文件是在D盘，所以会下载到D：\tmp\data\flowers下）。执行完后会看到下载的数据文件和生成的TFRecord文件，如图11-9所示。</p>
<p class="ziti3">这里包含5个训练数据文件、5个验证数据文件及一个标签文件。标签文件定义了整数标签和分类名称。</p>
<p class="ziti3">如果想将其他数据集转成TFRecord格式，可以参考上面的代码实现，这里不再展开介绍。</p>
<p class="ziti3">同样，也可以按照这个方法下载MNIST和cifar10数据集。如果需要下载imageNet数据集，则需要在image-net.org中注册一个账号，然后再运行下载脚本，大概有500GB，因此需要留出足够大的硬盘空间，并且下载时间会很长。</p>
<p class="ziti4">
<span class="yanse">2．处理slim数据集时的常见错误</span>
</p>
<p class="ziti3">由于有时网络有时会不稳定，因此使用上面讲的方法下载数据时往往会遇到如下错误，主要是由于没有下载完成的原因。</p>
<hr class="calibre6"/>
<pre class="ziti5">urllib.error.ContentTooShortError: &lt;urlopen error retrieval incomplete: 
got only
 64456280 out of 228813984 bytes&gt;</pre>
<hr class="calibre6"/>
<p class="ziti3">这表明由于网络原因数据包没有下载完整，有两种方法可以解决。</p>
<p class="ziti4">·如果你的网速较快的话，可以多运行几次，总有一次可以成功。</p>
<p class="ziti4">·可以将<a href="http://download.tensorflow.org/example_images/%20flower_photos.tgz" class="pcalibre calibre2">http://download.tensorflow.org/example_images/ flower_photos.tgz</a>
 网址放到下载工具（如迅雷等）里自行下载。</p>
<p class="ziti3">解压后的路径如图11-10所示。</p>
<div class="pic"><img alt="" src="Image00235.jpg" class="calibre4"/>
</div>
<p class="middle-img">图11-9　flowers文件夹的TFRecord数据集</p>
<div class="pic"><img alt="" src="Image00236.jpg" class="calibre4"/>
</div>
<p class="middle-img">图11-10　flowers数据集</p>
<p class="ziti3">然后来到download_and_convert_flowers.py第191行，注释掉下列代码即可。</p>
<hr class="calibre6"/>
<pre class="ziti5">#dataset_utils.download_and_uncompress_tarball(_DATA_URL,dataset_dir)</pre>
<hr class="calibre6"/>
<p class="ziti3">本书配套的代码中会有实例文件（见“11.5.3代码参考”文件夹）。</p>
<p class="ziti3">下载完成后，运行如下命令将刚下载的数据集转成TFRecord格式（以图11-10中的路径“/tmp/data/flowers”为例）：</p>
<hr class="calibre6"/>
<pre class="ziti5">D:\python\research\models\slim&gt;python download_and_convert_data.py --dataset_ name=flowers --dataset_dir=/tmp/data/flowers</pre>
<hr class="calibre6"/>
<h4 class="p3">11.5.4　实例84：利用slim读取TFRecord中的数据</h4>
<p class="ziti3">TFRecord文件创建好后，就可以读取文件中的数据了，本例将演示如何读取TFRecord中的数据，步骤如下。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">利用slim代码库里的函数读取TFRecord格式的数据并显示出来。</p>
<p class="ziti4">
<span class="yanse">1．定义slim数据集，创建provider</span>
</p>
<p class="ziti3">在图11-9中可以看到，有两个数据集train与validation。在读取时，需要指定一个数据集然后创建provider对象，接着就可以从provider里读取数据了，代码如下：</p>
<p class="ziti3">代码11-1　tfrecodertest</p>
<hr class="calibre6"/>
<pre class="ziti5">01 import tensorflow as tf
02 from datasets import flowers
03 import pylab 
04 
05 slim = tf.contrib.slim
06 
07 DATA_DIR="D:/own/python/flower_photosos" #指定flower数据集的路径
08 
09 #选择数据集validation
10 dataset = flowers.get_split('validation', DATA_DIR)
11 
12 #创建一个provider
13 provider = slim.dataset_data_provider.DatasetDataProvider(dataset)
14 #通过provider的get获得一条样本数据
15 [image, label] = provider.get(['image', 'label'])
16 print(image.shape)</pre>
<hr class="calibre6"/>
<p class="ziti3">上述代码中，先引入头文件，然后创建provider，通过get来获得image与label两个张量。这时并没有真的读到数据，只是一个构建图的过程。具体取数据则要通过session中启动队列线程后才可以。</p>
<p class="ziti3">provider是使用DatasetDataProvider类的实例化实现的，在DatasetDataProvider类中还可以有更多的设置：</p>
<hr class="calibre6"/>
<pre class="ziti5">class DatasetDataProvider(data_provider.DataProvider):
 
  def __init__(self,
               dataset,
               num_readers=1,
               reader_kwargs=None,
               shuffle=True,
               num_epochs=None,
               common_queue_capacity=256,
               common_queue_min=128,
               record_key='record_key',
               seed=None,
               scope=None):</pre>
<hr class="calibre6"/>
<p class="ziti3">必选参数是传入指定的数据集dataset，其他还包括指定几个并行读取器来读取数据num_readers、是否打乱顺序shuffle、指定数据源读取的循环次数num_epochs（None表示无限循环）、队列大小common_queue_capacity等。没有特殊要求的情况下，直接默认即可。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 本例演示的是只读取一条样本，在训练中需要按批次读取指定数量的样本，这时会需要配合tf.train.batch一起使用，tf.train.batch有个条件就是必须指定样本的固定大小，所以在传入时需要将变长的图片按固定大小调整。在slim的训练模型代码里有使用的例子，读者可以自己参考。另外，在第12章对抗神经网络里，超分辨率部分也有实例供读者学习、参考。</p>
<p class="ziti4">
<span class="yanse">2．启用session读取数据</span>
</p>
<p class="ziti3">在session中初始化变量之后，需要通过tf.train.start_queue_runners来启动队列线程。这时会有一个线程专门负责从磁盘里读图片数据，接着通过run来运行图节点image与label得到真实的数据。</p>
<p class="ziti3">代码11-1　tfrecodertest（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">￼17  sess = tf.InteractiveSession()
18  tf.global_variables_initializer().run()
19  #启动队列
20  tf.train.start_queue_runners()
21  #获取数据
22  image_batch, label_batch = sess.run([image, label])
23  #显示
24  print(label_batch)
25  pylab.imshow(image_batch)
26  pylab.show()</pre>
<hr class="calibre6"/>
<p class="ziti3">运行上述代码，输出的图片如图11-11所示。</p>
<hr class="calibre6"/>
<pre class="ziti5">(?, ?, 3)
1</pre>
<hr class="calibre6"/>
<div class="pic"><img alt="" src="Image00237.jpg" class="calibre4"/>
</div>
<p class="middle-img">图11-11　TFRecord例子</p>
<p class="ziti3">多运行几次发现，每次的结果都不一样，再次证实了默认是随机读取的。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 在处理大数据样本时，将数据转成TFRecord后使用线程来读取，是一个较常规的方式。千万不能像MNIST数据集读取那样一次都读入内存，内存会被样本耗尽，系统就无法处理其他的数据了。另外，除了使用 TFRecord方式以外，还可以从filenames中读取，通过异步读取文件，然后按批次的随机抽取指定样本数量，再输入到模型中来做模型参数的更新。</p>
<h4 class="p3">11.5.5　在slim中训练模型</h4>
<p class="ziti3">slim提供了很多便捷的方式，前面提到的全部模型在slim中都可以找到对应的代码实现。不仅如此，slim还共享了模型的训练代码，使用者不再需要关注模型代码，只需通过命令行方式即可完成训练、微调、测试等任务，大大方便了模型的产出。</p>
<p class="ziti3">对于linux用户，在slim的Scripts文件夹下还提供了模型下载、训练、预训练、微调、测试等一条龙的完整shell脚本。如果你用的是Windows，也可以在命令行下一条一条地复制命令并执行命令。</p>
<hr class="calibre6"/>
<pre class="ziti5">D:\python\research\models\slim&gt;python train_image_classifier.py --train_dir=
log/in3flower --dataset_name=flowers --dataset_split_name=train –datas
et_dir=/tmp/data/flowers/flower_photosos --model_name=inception_v3 </pre>
<hr class="calibre6"/>
<p class="ziti3">关于shell脚本代码，不再逐条解释，下面举例演示使用命令行来训练模型的相关操作。</p>
<p class="ziti4">
<span class="yanse">1．从头训练</span>
</p>
<p class="ziti3">训练模型的代码被放在slim下的train_image_classifier.py文件里，这里用flower数据集来训练Inception_v3网络结构的深度神经网络模型。在命令行中执行如下命令：</p>
<p class="ziti3">参数说明如下。</p>
<p class="ziti4">·train_dir：是要生成模型的路径。</p>
<p class="ziti4">·dataset_name：数据集名字。</p>
<p class="ziti4">·dataset_split_name：数据集中的哪一部分是validation还是train。</p>
<p class="ziti4">·dataset_dir：数据集路径。</p>
<p class="ziti4">·model_name：模型名字。</p>
<p class="ziti3">这里只列出了主要的参数，其他的参数可以仿照shell脚本中的例子，如果读者想知道全部的参数，可参看train_image_classifier.py文件。也可以修改train_image_classifier.py文件，添加自己喜欢的参数。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 dataset_name、dataset_split_name、model_name的名字不是随意命名的，必须与代码中的名字对应。如果使用自己的数据集，则需要在slim中的dataset文件夹下仿照其他的数据集加一个.py文件，然后也可以用train_image_classifier.py来运行。当然读者也可以不使用train_image_classifier.py，直接自己编写代码载入数据集。</p>
<p class="ziti4">
<span class="yanse">2．预训练模型</span>
</p>
<p class="ziti3">预训练就是在别人训练好的模型基础上进行二次训练，以得到自己需要的模型。可以帮你省去大量的时间。一些高质量的模型都是通过了大量的数据样本训练而来的。GitHub上提供了很多训练好的模型，可用于预训练，可以在<a href="https://github.com/TensorFlow/models/%20tree/master/research/slim#Pretrained" class="pcalibre calibre2">https://github.com/TensorFlow/models/ tree/master/research/slim#Pretrained</a>
 中下载。</p>
<p class="ziti3">该链接是TensorFlow里slim模块在GitHub中的页面，页面中的表的部分内容如图11-12所示。</p>
<div class="pic"><img alt="" src="Image00238.jpg" class="calibre4"/>
</div>
<p class="middle-img">图11-12　模型下载截图</p>
<p class="ziti3">图11-12中的表格内，Checkpoint列是模型下载的链接。这些模型都是在ILSVRC-2012-CLS（ImageNet）数据集上训练而来的，这个数据集共500GB，共分为1000个类的图片。想要了解更多关于ImageNet的信息，可以看网站<a href="http://www.image-net.org/%20challenges/LSVRC/2012/" class="pcalibre calibre2">http://www.image-net.org/ challenges/LSVRC/2012/</a>
 。</p>
<p class="ziti3">下载完预训练模型后，只需要在11.5.5节“从头训练”的命令中添加一个参数——checkpoint_path即可。</p>
<hr class="calibre6"/>
<pre class="ziti5">--checkpoint_path =模型的路径</pre>
<hr class="calibre6"/>
<p class="ziti3">--checkpoint_path里的模型用于预训练模型的参数初始化。在训练过程中不会改变，新产生的模型会被保存在--train_dir指定的路径下面。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 预训练时使用的样本必须与原来的输入尺寸和输出的分类个数一致。这些可下载的模型都是要分成1000类的，如果你不想分这么多类，可以使用下面微调的方法。</p>
<p class="ziti4">
<span class="yanse">3．微调fine-tuning</span>
</p>
<p class="ziti3">上述的预训练模型都是在imagenet上训练的，最终输出的是1000个分类，如果我们想使用预训练模型训练自己的数据集时，就要微调了。</p>
<p class="ziti3">在微调过程中，需要将原有模型中的最后一层去掉，换成自己的数据集对应的分类层。例如我们要训练flowers数据集，就需要将1000个输出换成10个输出。</p>
<p class="ziti3">具体做法如下。</p>
<p class="ziti3">（1）通过参数--checkpoint_exclude_scopes指定载入预训练模型时哪一层的权重不被载入。</p>
<p class="ziti3">（2）再通过--trainable_scopes参数指定对哪一层的参数进行训练。当--trainable_scopes出现时，没有被指定训练的参数将在训练中被冻结。</p>
<p class="ziti3">举例：使用inception_v3的模型进行微调，使其可以训练flowers数据集。将下载好的模型inception_v3.ckpt解压后放在当前目录文件夹inception_v3下，通过cmd进入命令行来到models\slim文件夹下，运行如下命令：</p>
<hr class="calibre6"/>
<pre class="ziti5">D:\own\python\research\models\slim&gt;python train_image_classifier.py --train_ dir=log/in3--dataset_name=flowers--dataset_split_name=train --dataset_dir= D:\own\python\flower_photosos--model_name=inception_v3--checkpoint_path=
inception_v3/inception_v3.ckpt --checkpoint_exclude_scopes=InceptionV3/ Logits,InceptionV3/AuxLogits --trainable_scopes=InceptionV3/Logits,InceptionV3/ AuxLogits</pre>
<hr class="calibre6"/>
<p class="ziti3">在例子中，--checkpoint_path里的模型会被载入，将权重初始化成模型里的值，同时--checkpoint_exclude_scopes限制了最后一层没有被初始化成模型里的参数。--trainable_scopes指定了只训练最后新加的一层，这样在训练过程中被冻结的其他参数具有原来训练好的合适值，而新加的一层则通过迭代在不断地优化自己的参数。</p>
<p class="ziti3">在微调的过程中，还可以通过在上面命令中加入：</p>
<hr class="calibre6"/>
<pre class="ziti5">--max_number_of_steps=500</pre>
<hr class="calibre6"/>
<p class="ziti3">来指定训练步数。如果没有指定训练步数，默认会一直训练下去。更多的参数，可参看train_image_classifier.py的源码。另外，slim的Scripts中还有使用模型来识别图片的例子，读者可以一起配合着学习。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 有时会报初始化失败的错误：</p>
<hr class="calibre6"/>
<pre class="ziti5">E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\ stream _executor\cuda\cuda_dnn.cc:359] could not create cudnn handle: CUDNN_STATUS_
NOT_INITIALIZED
2017-05-02 17:48:48.334466: E c:\tf_jenkins\home\workspace\release-win\ device\ gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:366] error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2017-05-02 17:48:48.343454: E c:\tf_jenkins\home\workspace\release-win\ device\gpu\ os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:326] could not destroy cudnn handle: CUDNN_STATUS_
BAD_PARAM</pre>
<hr class="calibre6"/>
<p class="ziti4">这种问题表明显卡没有启动，重启计算机即可</p>
<p class="ziti4">
<span class="yanse">4．评估模型</span>
</p>
<p class="ziti3">eval_image_classifier.py文件是已经封装好用来评估模型的。下面还是以上面的flower集合微调Inception_v3的模型为例，评估模型的命令如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">python eval_image_classifier.py--checkpoint_path=log/in3/model.ckpt
-3416059--eval_dir=log/in3/model.ckpt-3416059--dataset_name=flowers
--dataset_split_name=validation--dataset_dir=D:\own\python\flower_
photosos--model_name=inception_v3</pre>
<hr class="calibre6"/>
<p class="ziti3">其中，指定路径的文件为log/in3/model.ckpt-3416059，即在微调中训练出来的模型文件。</p>
<p class="ziti4">
<span class="yanse">5．打包模型</span>
</p>
<p class="ziti3">训练好的模型可以被打包到各个平台上使用，无论是iOS、Android还是Linux系列。具体是通过一个bazel开源工具来实现的。这部分内容不在本书的范围之内，有兴趣的读者可以自行研究。</p>
<p class="ziti3">更多的内容可以参考链接<a href="https://github.com/tensorflow/models/tree/master/research/%20slim#Export" class="pcalibre calibre2">https://github.com/tensorflow/models/tree/master/research/ slim#Export</a>
 。</p>
<div class="calibre1">本书由「<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body>
</html>

<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h3 class="p">5.4　训练模型并输出中间状态参数</h3>
<p class="ziti3">现在开始真正地训练模型了，先定义训练相关的参数。</p>
<p class="ziti3">下面代码中，第20行中，training_epochs代表要把整个训练样本集迭代25次；第21行中，batch_size代表在训练过程中一次取100条数据进行训练；第22行中，display_step代表每训练一次就把具体的中间状态显示出来。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 batch_size参数代表的意义很关键，在深度学习中，都是将数据按批次地向里面放的。在后面章节中还会详细介绍这么做的目的。</p>
<p class="ziti3">参数定义好后，启动一个session就可以开始训练过程了。session中有两个run，第一个run是运行初始化，第二个run是运行具体的运算模型。模型运算之后便将里面的状态打印出来。</p>
<p class="ziti3">代码5-2　MNIST分类（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">20 training_epochs = 25
21 batch_size = 100
22 display_step = 1
23 
24 # 启动session
25 with tf.Session() as sess:
26     sess.run(tf.global_variables_initializer())# Initializing OP
27 
28     # 启动循环开始训练
29     for epoch in range(training_epochs):
30         avg_cost = 0.
31         total_batch = int(mnist.train.num_examples/batch_size)
32         # 循环所有数据集
33         for i in range(total_batch):
34             batch_xs, batch_ys = mnist.train.next_batch(batch_size)
35             # 运行优化器
36             _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,
37                                                           y: batch_ys})
38             # 计算平均loss值
39             avg_cost += c / total_batch
40         # 显示训练中的详细信息
41         if (epoch+1) % display_step == 0:
42             print ("Epoch:", '%04d' % (epoch+1), "cost=", "{:.9f}".
            format(avg_cost))
43 
44     print( " Finished!")</pre>
<hr class="calibre6"/>
<p class="ziti3">执行上面的代码，会输出如下信息：</p>
<hr class="calibre6"/>
<pre class="ziti5">Epoch: 0001 cost= 9.923389743
Epoch: 0002 cost= 4.695022035
Epoch: 0003 cost= 3.076164273
Epoch: 0004 cost= 2.417567778
Epoch: 0005 cost= 2.052902991
Epoch: 0006 cost= 1.816404106
Epoch: 0007 cost= 1.649224558
Epoch: 0008 cost= 1.523894480
Epoch: 0009 cost= 1.425924496
Epoch: 0010 cost= 1.346838083
Epoch: 0011 cost= 1.281203090
Epoch: 0012 cost= 1.225851107
Epoch: 0013 cost= 1.178292338
Epoch: 0014 cost= 1.136689923
Epoch: 0015 cost= 1.100095906
Epoch: 0016 cost= 1.067396342
Epoch: 0017 cost= 1.038121746
Epoch: 0018 cost= 1.011435861
Epoch: 0019 cost= 0.987299248
Epoch: 0020 cost= 0.965228878
Epoch: 0021 cost= 0.944723253
Epoch: 0022 cost= 0.925947570
Epoch: 0023 cost= 0.908483106
Epoch: 0024 cost= 0.892120825
Epoch: 0025 cost= 0.877055534
Finished!</pre>
<hr class="calibre6"/>
<p class="ziti3">这里输出的中间状态是cost损失值。读者也可以把自己关心的内容打印出来。可以看到，从第1次迭代到第25次迭代的损失值在逐渐减小，最终的误差只有0.8。</p>
<div class="calibre1">本书由「<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body>
</html>

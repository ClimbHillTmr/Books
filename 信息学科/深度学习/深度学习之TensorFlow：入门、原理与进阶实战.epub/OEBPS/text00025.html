<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h3 class="p">4.5　配置分布式TensorFlow</h3>
<p class="ziti3">在大型的数据集上进行神经网络的训练，往往需要更大的运算资源，而且还要耗费若干天才能完成运算量。</p>
<p class="ziti3">TensorFlow提供了一个可以分布式部署的模式，将一个训练任务拆成多个小任务，分配到不同的计算机上来完成协同运算，这样使用计算机群运算来代替单机计算，可以使训练时间大大缩短。</p>
<h4 class="p3">4.5.1　分布式TensorFlow的角色及原理</h4>
<p class="ziti3">要想配置TensorFlow为分布训练，需要先了解TensorFlow中关于分布式的角色分配。</p>
<p class="ziti4">·ps：作为分布式训练的服务端，等待各个终端（supervisors）来连接。</p>
<p class="ziti4">·worker：在TensorFlow的代码注释中被称为supervisors，作为分布式训练的运算终端。</p>
<p class="ziti4">·chief supervisors：在众多运算终端中必须选择一个作为主要的运算终端。该终端是在运算终端中最先启动的，它的功能是合并各个终端运算后的学习参数，将其保存或载入。</p>
<p class="ziti3">每个具体角色网络标识都是唯一的，即分布在不同IP的机器上（或者同一个机但不同的端口）。</p>
<p class="ziti3">在实际运行中，各个角色的网络构建部分代码必须100%的相同。三者的分工如下：</p>
<p class="ziti4">·服务端作为一个多方协调者，等待各个运算终端来连接。</p>
<p class="ziti4">·chief supervisors会在启动时统一管理全局的学习参数，进行初始化或从模型载入。</p>
<p class="ziti4">·其他的运算终端只是负责得到其对应的任务并进行计算，并不会保存检查点，用于TensorBoard可视化中的summary日志等任何参数信息。</p>
<p class="ziti3">整个过程都是通过RPC协议来通信的。</p>
<h4 class="p3">4.5.2　分布部署TensorFlow的具体方法</h4>
<p class="ziti3">配置过程中，首先需要建一个server，在server中会将ps及所有worker的IP端口准备好。接着，使用tf.train.Supervisor中的managed_session来管理一个打开的session。session中只是负责运算，而通信协调的事情就都交给supervisor来管理了。</p>
<h4 class="p3">4.5.3　实例20：使用TensorFlow实现分布式部署训练</h4>
<p class="ziti3">下面开始实现一个分布式训练的网络模型。本例以“代码4-8线性回归的TensorBoard可视化.py”为原型，在其中添加代码将其改成分布式。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">在本机通过3个端口来建立3个终端，分别是一个ps，两个worker，实现TensorFlow的分布式运算。</p>
<p class="ziti3">具体步骤如下。</p>
<p class="ziti4">
<span class="yanse">1．为每个角色添加IP地址和端口，创建server</span>
</p>
<p class="ziti3">在一台机器上开3个不同的端口，分别代表ps、chief supervisors 和worker。角色的名称用strjob_name表示。以ps为例，代码如下：</p>
<p class="ziti3">代码4-15　ps</p>
<hr class="calibre6"/>
<pre class="ziti5">01 ……
02 #定义IP和端口 
03 strps_hosts="localhost:1681"
04 strworker_hosts="localhost:1682,localhost:1683"
05 
06 #定义角色名称
07 strjob_name = "ps"
08 task_index = 0
09 #将字符串转成数组
10 ps_hosts = strps_hosts.split(',')
11 worker_hosts = strworker_hosts.split(',')
12 cluster_spec = tf.train.ClusterSpec({'ps': ps_hosts,'worker': worker_
hosts})
13 #创建server
14 server = tf.train.Server(
15                     {'ps': ps_hosts,'worker': worker_hosts},
16                     job_name=strjob_name,
17                     task_index=task_index)</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 没有网络基础的读者可能看不明白localhost，说好的IP地址呢？localhost即是本机域名的写法，等同于127.0.0.1（本机IP）。如果是跨机器来做分布式训练，直接写成对应机器的IP地址即可。</p>
<p class="ziti4">
<span class="yanse">2．为ps角色添加等待函数</span>
</p>
<p class="ziti3">ps角色使用server.join函数进行线程挂起，开始接收连接消息。</p>
<p class="ziti3">代码4-15　ps（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">18 #ps角色使用join进行等待
19 if strjob_name == 'ps':
20   print("wait")
21   server.join()</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse">3．创建网络结构</span>
</p>
<p class="ziti3">与正常的程序不同，在创建网络结构时，使用tf.device函数将全部的节点都放在当前任务下。</p>
<p class="ziti3">在tf.device函数中的任务是通过tf.train.replica_device_setter来指定的。</p>
<p class="ziti3">在tf.train.replica_device_setter中使用worker_device来定义具体任务名称；使用cluster的配置来指定角色及对应的IP地址，从而实现管理整个任务下的图节点。代码如下：</p>
<p class="ziti3">代码4-15　ps（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">22 with tf.device(tf.train.replica_device_setter(
23                worker_device="/job:worker/task:%d" % task_index,
24                cluster=cluster_spec)):
25     X = tf.placeholder("float")
26     Y = tf.placeholder("float")
27     # 模型参数
28     W = tf.Variable(tf.random_normal([1]), name="weight")
29     b = tf.Variable(tf.zeros([1]), name="bias")
30     
31     global_step = tf.train.get_or_create_global_step() #获得迭代次数
32     
33     # 前向结构
34     z = tf.multiply(X, W)+ b
35     tf.summary.histogram('z',z)                    #将预测值以直方图显示
36     #反向优化
37     cost =tf.reduce_mean( tf.square(Y - z))
38     tf.summary.scalar('loss_function', cost)    #将损失以标量显示
39     learning_rate = 0.01
40     optimizer = tf.train.GradientDescentOptimizer(learning_rate).
    minimize(cost,global_step=global_step) #梯度下降
41 
42     saver = tf.train.Saver(max_to_keep=1)
43     merged_summary_op = tf.summary.merge_all()  #合并所有summary
44    
45     init = tf.global_variables_initializer()</pre>
<hr class="calibre6"/>
<p class="ziti3">为了使载入检查点文件时能够同步循环次数，这里加了一个global_step变量，并将其放到优化器中。这样，每次运行一次优化器，global_step就会自动获得当期迭代的次数。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 init = tf.global_variables_initializer（）这个代码是将其前面的变量全部初始化，如果后面再有变量，则不会被初始化。所以，一般要将init = tf.global_variables_ initializer（）这个代码放在最后。这是个很容易出错的地方，常常令开发者找不到头绪。读者也可以试着在最前面运行，看看会发生什么。</p>
<p class="ziti4">
<span class="yanse">4．创建Supervisor，管理session</span>
</p>
<p class="ziti3">代码4-15　ps（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">46 # 定义参数
47 training_epochs = 2200
48 display_step = 2
49 
50 sv = tf.train.Supervisor(is_chief=(task_index == 0),#0号worker为chief
51                              logdir="log/super/",
52                              init_op=init,
53                              summary_op=None,
54                              saver=saver,
55                              global_step=global_step,
56                              save_model_secs=5)
57 
58 #连接目标角色创建session
59 with sv.managed_session(server.target) as sess:</pre>
<hr class="calibre6"/>
<p class="ziti3">在tf.train.Supervisor函数中，is_chief表明了是否为chief supervisors角色。这里将task_index=0的worker设置成chief supervisors。</p>
<p class="ziti3">logdir为检查点文件和summary文件保存的路径。</p>
<p class="ziti3">init_op表示使用初始化变量的函数。</p>
<p class="ziti3">saver需要将保存检查点的saver对象传入，supervisor就会自动保存检查点文件。如果不想自动保存，可以设为None。</p>
<p class="ziti3">同理，summary_op也是自动保存summary文件。这里设为None，表示不自动保存。</p>
<p class="ziti3">save_model_secs为保存检查点文件的时间间隔。这里设为5，表示每5秒自动保存一次检查点文件。以上代码，为了让分布运算的效果明显一些，将迭代次数改成了2200，使其运算时间变长。</p>
<p class="ziti4">
<span class="yanse">5．迭代训练</span>
</p>
<p class="ziti3">session中的内容与以前一样，直接迭代训练即可。由于使用了supervisor管理session，将使用sv.summary_computed函数来保存summary文件。同样，如想要手动保存检测点文件，也可以使用sv.saver.save。代码如下：</p>
<p class="ziti3">代码4-15　ps（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">60 print("sess ok")
61     print(global_step.eval(session=sess))
62     
63     for epoch in range(global_step.eval(session=sess),training_
    epochs*len(train_X)):
64     
65         for (x, y) in zip(train_X, train_Y):
66             _, epoch = sess.run([optimizer,global_step] ,feed_dict={X: 
            x, Y: y})
67             #生成summary
68             summary_str = sess.run(merged_summary_op,feed_dict={X: x, 
            Y: y});
69             #将summary 写入文件
70             sv.summary_computed(sess, summary_str,global_step=epoch)
71             if epoch % display_step == 0:
72                 loss = sess.run(cost, feed_dict={X: train_X, Y:train_Y})
73                 print ("Epoch:", epoch+1, "cost=", loss,"W=", sess.run(W), 
                "b=", sess.run(b))
74                 if not (loss == "NA" ):
75                     plotdata["batchsize"].append(epoch)
76                     plotdata["loss"].append(loss)
77                 
78     print (" Finished!")
79     sv.saver.save(sess,"log/mnist_with_summaries/"+"sv.cpk",global_
    step=epoch)
80 
81 sv.stop()</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 （1）在设置自动保存检查点文件后，手动保存仍然有效。</p>
<p class="ziti4">（2）在运行一半后终止，再运行supervisor时会自动载入模型的参数，不需要手动调用saver.restore。</p>
<p class="ziti4">（3）在session中，不需要再运行tf.global_variables_initializer函数。原因是supervisor在建立时会调用传入的init_op进行初始化，如果加了sess.run（tf.global_ variables_initializer（）），则会导致所载入模型的变量被二次清空。</p>
<p class="ziti4">
<span class="yanse">6．建立worker文件</span>
</p>
<p class="ziti3">将文件复制两份，分别起名为“4-16 worker.py”与“4-17 worker2.py”，将角色名称修改成worker，并将“4-16 worker2.py”中的task_index设为1。</p>
<p class="ziti3">代码4-16　worker</p>
<hr class="calibre6"/>
<pre class="ziti5">……
#定义角色名称
strjob_name = "worker"
task_index = 0
……</pre>
<hr class="calibre6"/>
<p class="ziti3">代码4-17　worker2</p>
<hr class="calibre6"/>
<pre class="ziti5">……
#定义角色名称
strjob_name = "worker"
task_index = 1
……</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 这个例子中使用了summary的一些方法将运行时态的数据保存起来，以便于使用TensorBoard进行查看（见4.1.16节）。但在分布式部署时，使用该功能还需要注意以下几点：</p>
<p class="ziti4">（1）不能使用sv.summary_computed，因为worker2不是chief supervisors，在worker2中是不会为supervisor对象构造默认summary_writer的（所有的summary信息都要通过该对象进行写入），所以即使调用summary_computed也无法执行下去，程序会报错。</p>
<p class="ziti4">（2）手写控制summary与检查点文件保存时，需要将chief supervisors以外的worker全部去掉才可以。可以使用supervisor按时间间隔保存的形式来管理，这样用一套代码就可以解决了。</p>
<p class="ziti4">
<span class="yanse">7．部署运行</span>
</p>
<p class="ziti3">（1）在Spyder中先将“4-15 ps.py”文件运行起来，选择菜单Consoles|Open an IPython console命令，新打开一个Consoles，如图4-7所示。</p>
<div class="pic"><img alt="" src="Image00067.jpg" class="calibre4"/>
</div>
<p class="middle-img">图4-7 Consoles菜单</p>
<p class="ziti3">（2）在Spyder面板的右下角（见图2-13中的输出栏），可以看到在原有标题为“Console 1/A”标签旁边又多了一个“Console 2/A”标签（如图4-8所示），单击该标签，使其处于激活状态。</p>
<div class="pic"><img alt="" src="Image00068.jpg" class="calibre4"/>
</div>
<p class="middle-img">图4-8　Consoles 2/A标签</p>
<p class="ziti3">（3）运行4-17 worker2.py文件。最后按照“4-17worker2.py”文件启动的方式，启动4-16 worker.py”文件，这时3个窗口的显示内容分别如下：</p>
<p class="ziti4">·“4-16worker.py”文件对应窗口显示正常的训练信息。</p>
<hr class="calibre6"/>
<pre class="ziti5">……
Epoch: 8000 cost= 0.0754263 W= [ 2.01029539] b= [-0.00388618]
Epoch: 8002 cost= 0.074845 W= [ 2.00651097] b= [ 0.00453186]
Epoch: 8003 cost= 0.0748089 W= [ 2.00529122] b= [ 0.00281144]
Epoch: 8005 cost= 0.0747555 W= [ 2.00324082] b= [ 0.00635108]
Epoch: 8007 cost= 0.075026 W= [ 2.00662613] b= [-0.00956773]
Epoch: 8009 cost= 0.0749311 W= [ 2.00585985] b= [-0.006533]
Epoch: 8010 cost= 0.0748186 W= [ 2.00469637] b= [-0.00152527]
Epoch: 8011 cost= 0.0750369 W= [ 2.0065136] b= [-0.02676161]
Epoch: 8012 cost= 0.0758979 W= [ 2.0068512] b= [-0.02852018]
Epoch: 8013 cost= 0.0759059 W= [ 2.00671506] b= [-0.02870713]
Epoch: 8015 cost= 0.0753608 W= [ 2.0055182] b= [-0.01959283]
Epoch: 8018 cost= 0.0760464 W= [ 2.00559783] b= [-0.03230772]
Epoch: 8021 cost= 0.0758819 W= [ 2.00522184] b= [-0.02836083]
Epoch: 8023 cost= 0.0758949 W= [ 2.00778055] b= [-0.01191433]
Epoch: 8026 cost= 0.0752242 W= [ 2.00646138] b= [-0.01574964]
Epoch: 8028 cost= 0.0751021 W= [ 2.00708318] b= [-0.01172168]
Epoch: 8030 cost= 0.0749788 W= [ 2.0083425] b= [-0.00503741]
Epoch: 8034 cost= 0.0750521 W= [ 2.00837708] b= [-0.0084667]
Epoch: 8035 cost= 0.0750075 W= [ 2.01157689] b= [ 0.00467709]
Epoch: 8037 cost= 0.0751661 W= [ 2.01191807] b= [ 0.0159377]
Epoch: 8038 cost= 0.0750556 W= [ 2.01164842] b= [ 0.01059892]
Epoch: 8040 cost= 0.0753085 W= [ 2.01313496] b= [ 0.01954099]
Epoch: 8042 cost= 0.0753466 W= [ 2.01260543] b= [ 0.02123925]
……</pre>
<hr class="calibre6"/>
<p class="ziti3">可以看到循环的次数并不是连续的，跳过的步骤被分配到worker2中去运算了。</p>
<p class="ziti4">·“4-17worker2.py”文件对应窗口显示的信息如下：</p>
<hr class="calibre6"/>
<pre class="ziti5">INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:
None, ready: Variables not initialized: weight, bias, global_step
INFO:tensorflow:Starting queue runners.
……
Epoch: 8003 cost= 0.0977818 W= [ 2.00529122] b= [ 0.00281144]
Epoch: 8005 cost= 0.0979236 W= [ 2.00324082] b= [ 0.00635108]
Epoch: 8007 cost= 0.0978101 W= [ 2.0065136] b= [-0.01009204]
Epoch: 8012 cost= 0.0985371 W= [ 2.00671506] b= [-0.02870713]
Epoch: 8015 cost= 0.0981559 W= [ 2.0055182] b= [-0.01959283]
Epoch: 8017 cost= 0.0986897 W= [ 2.00519013] b= [-0.02992464]
Epoch: 8018 cost= 0.0987787 W= [ 2.00559783] b= [-0.03128441]
Epoch: 8020 cost= 0.0988223 W= [ 2.00550485] b= [-0.02906012]
Epoch: 8022 cost= 0.0985962 W= [ 2.00522184] b= [-0.02918861]
Epoch: 8024 cost= 0.0982481 W= [ 2.00616717] b= [-0.02256276]
Epoch: 8025 cost= 0.0977918 W= [ 2.00778055] b= [-0.01191433]
Epoch: 8026 cost= 0.0979684 W= [ 2.00646138] b= [-0.01574964]
Epoch: 8028 cost= 0.0978234 W= [ 2.00708318] b= [-0.01172168]
Epoch: 8030 cost= 0.0976372 W= [ 2.00842071] b= [-0.00485691]
Epoch: 8031 cost= 0.0976208 W= [ 2.00859952] b= [-0.00408681]
Epoch: 8032 cost= 0.0976431 W= [ 2.0083425] b= [-0.00503741]
Epoch: 8034 cost= 0.097557 W= [ 2.01164842] b= [ 0.01059892]
Epoch: 8039 cost= 0.0975473 W= [ 2.01065278] b= [ 0.00720035]
Epoch: 8040 cost= 0.0977502 W= [ 2.01313496] b= [ 0.01954099]
Epoch: 8042 cost= 0.0978443 W= [ 2.01260543] b= [ 0.02123925]
……</pre>
<hr class="calibre6"/>
<p class="ziti3">显示结果中有警告输出，这是因为在构建supervisor时没有填写local_init_op参数，该参数的意思是在创建worker实例时，初始化本地变量。由于例子中没有填，系统就会自动初始化，并给出警告提示。</p>
<p class="ziti3">从日志中可以看到worker2 与chief supervisors的迭代序号近似互补，为什么没有绝对互补呢？可能与supervisor中的同步算法有关。</p>
<p class="ziti3">分布运算目的是为了提高整体运算速度，如果同步epoch的准确度需要以牺牲总体运算速度为代价，自然很不合适。所以更合理的推断是因为单机单次的运算太快迫使算法使用了更宽松的同步机制。</p>
<p class="ziti3">重要的一点是对于指定步数的学习参数b和w是一致的（如第8040步，学习参数是相同的，都为W= [ 2.01313496] b= [ 0.01954099]），这表明两个终端是在相同的起点上进行运算的。</p>
<p class="ziti4">·对于4-15ps.py文件，其对应窗口则是一直静默着只显示打印的那句wait，因为它只负责连接不参与运算。</p>
<div class="calibre1">本书由「<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body>
</html>

<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h3 class="p">10.9　变分自编码</h3>
<p class="ziti3">前面所描述的自编码可以降维重构样本，在这个基础上我们来学习一个更强大的自编码网络。</p>
<h4 class="p3">10.9.1　什么是变分自编码</h4>
<p class="ziti3">变分自编码学习的不再是样本的个体，而是学习样本的规律。这样训练出来的自编码不单具有重构样本的功能，还具有仿照样本的功能。</p>
<p class="ziti3">听起来这么强大的功能，到底是怎么做到的呢？下面我们来讲讲它的原理。</p>
<p class="ziti3">变分自编码，其实就是在编码过程中改变了样本的分布（“变分”可以理解为改变分布）。前面所说的“学习样本的规律”，具体指的就是样本的分布，假设我们知道样本的分布函数，就可以从这个函数中随便取一个样本，然后进行网络解码层前向传导，这样就可以生成一个新的样本。</p>
<p class="ziti3">为了得到这个样本的分布函数，模型训练的目的将不再是样本本身，而是通过加一个约束项，将网络生成一个服从于高斯分布的数据集，这样按照高斯分布里的均值和方差规则就可以任意取相关的数据，然后通过解码层还原成样本。</p>
<h4 class="p3">10.9.2　实例82：使用变分自编码模拟生成MNIST数据</h4>
<p class="ziti3">对于变分自编码，好多文献都给出了一堆晦涩难懂的公式，其实里面真正的公式只有一个——KL离散度的计算。而它也属于成熟的式子，就跟交叉熵一样，直接拿来用就可以。</p>
<p class="ziti3">公式本来是语言的高度概括，而如果一篇文章全是公式没有语言就会令人难以理解，本节会通过代码加上语言描述，让这部分知识学习起来不会感觉晦涩难懂。</p>
<p class="ziti3">本例共分如下几个步骤，下面就来一一操作。</p>
<p class="ziti3">
<span class="yanse">实例描述</span>
</p>
<p class="ziti3">使用变分自编码模型进行模拟MNIST数据的生成。</p>
<p class="ziti4">
<span class="yanse">1．引入库，定义占位符</span>
</p>
<p class="ziti3">本例建立的网络与之前略有不同，编码器为两个全连接层，第一个全连接层由784个维度的输入变化256个维度的输出；第二个全连接层并列连接了两个输出网络（mean与lg_var），每个网络都输出了两个维度的输出。然后将两个输出通过一个公式的计算，输入到以一个2节点为开始的解码部分，接着后面为两个全连接层的解码器，第一层由两个维度的输入到256个维度的输出，第二层由256个维度的输入到784个维度的输出，如图10-17所示。</p>
<div class="pic"><img alt="" src="Image00217.jpg" class="calibre4"/>
</div>
<p class="middle-img">图10-17　变分自编码器层次</p>
<p class="ziti3">具体的计算公式，后面会有详细介绍。</p>
<p class="ziti3">在下面的代码中与前面代码不同，引入了一个scipy库，在后面可视化时会用到。头文件引入之后，定义操作符x和z。x用于原始的图片输入，z用于中间节点解码器的输入。</p>
<p class="ziti3">代码10-8　变分自编码</p>
<hr class="calibre6"/>
<pre class="ziti5">01 import numpy as np
02 import tensorflow as tf
03 import matplotlib.pyplot as plt
04 from scipy.stats import norm
05 
06 from tensorflow.examples.tutorials.mnist import input_data
07 mnist = input_data.read_data_sets("/data/") #, one_hot=True)
08 
09 n_input = 784
10 n_hidden_1 = 256
11 n_hidden_2 = 2
12 
13 x = tf.placeholder(tf.float32, [None, n_input])
14 
15 zinput = tf.placeholder(tf.float32, [None, n_hidden_2])</pre>
<hr class="calibre6"/>
<p class="ziti3">zinput是个占位符，在后面要通过它输入分布数据，用来生成模拟样本数据。</p>
<p class="ziti4">
<span class="yanse">2．定义学习参数</span>
</p>
<p class="ziti3">由于这次的网络结构不同，所以定义的参数也有变化，mean_w1与mean_b1是生成mean的权重，log_sigma_w1与log_sigma_b1是生成log_sigma的权重。</p>
<p class="ziti3">代码10-8　变分自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">16 weights = {
17 
18     'w1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],
19                                    stddev=0.001)),
20     'b1': tf.Variable(tf.zeros([n_hidden_1])),
21 
22     'mean_w1': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],
23                                    stddev=0.001)),
24     'log_sigma_w1': tf.Variable(tf.truncated_normal([n_hidden_1, n_
    hidden_2],
25                                    stddev=0.001)),    
26     
27     'w2': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_1],
28                                    stddev=0.001)),
29 
30     'b2': tf.Variable(tf.zeros([n_hidden_1])),
31     'w3': tf.Variable(tf.truncated_normal([n_hidden_1, n_input],
32                                    stddev=0.001)),
33 
34     'b3': tf.Variable(tf.zeros([n_input])),
35 
36     'mean_b1': tf.Variable(tf.zeros([n_hidden_2])),
37 
38     'log_sigma_b1': tf.Variable(tf.zeros([n_hidden_2]))
39 }</pre>
<hr class="calibre6"/>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 这里初始化w的权重与以往不同，使用了很小的值（方差为0.001的truncated_ normal）。这里设置得非常小心，由于在算KL离散度时计算的是与标准高斯分布的距离，如果网络初始生成的模型均值方差都很大，那么与标准高斯分布的距离就会非常大，这样会导致模型训练不出来，生成NAN的情况。</p>
<p class="ziti4">
<span class="yanse">3．定义网络结构</span>
</p>
<p class="ziti3">按照图10-17的描述，网络节点可以按照以下代码来定义，在变分解码器中为训练的中间节点赋予了特殊的意义，让它们代表均值和方差，并将它们所代表的数据集向着标准高斯分布数据集靠近（也就是原始数据是样本，高斯分布数据是标签），然后可以使用KL离散度公式，来计算它所代表的集合与标准的高斯分布集合（均值是0，方差为1的正态分布）间的距离，将这个距离当成误差，让它最小化从而优化网络参数。</p>
<p class="ziti3">这里的方差节点不是真正意义的方差，是取了log之后的，所以会有tf.exp（z_log_sigma_sq）的变换，是取得方差的值，再通过tf.sqrt将其开平方得到标准差。用符合标准正太分布的一个数乘以标准差加上均值，就使这个数成为符合（z_mean，sigma）数据分布集合里的一个点（z_mean是指网络生成均值，sigma是指网络生成的z_log_sigma_sq变换后的值）。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 输出的值当成任意一个意义，并通过训练得到对应的关系。具体做法为：将具有代表该意义的值代入相应的公式（该公式要求必须能够支持反向传播），计算公式输出值与目标值的误差，并将误差放到优化器里，然后通过多次迭代的方式进行训练即可。</p>
<p class="ziti3">到此，完成了编码阶段。将原始数据编码输出3个值：</p>
<p class="ziti4">·一个是表示该数据分布的均值。</p>
<p class="ziti4">·一个是表示该数据分布的方差。</p>
<p class="ziti4">·还有一个是得到了该数据分布中的一个实际的点z。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 这里的变换对应的知识点是：假如一个符合高斯分布的数据集均值、标准差为（m，sigma），其里面的某个点，可以通过一个符合标准高斯分布（0，1）中的点x，通过m+x×sigma的方式转化而成。</p>
<p class="ziti3">但这是在一个假设背景下完成的，假设数据分布属于高斯分布。我们现在无法保证转换后的数据分布符合高斯分布，则可以通过测量输出值代表的数据集与标准高斯分布数据集之间的差距，利用神经网络来将其训练成符合高斯分布的数据集。</p>
<p class="ziti3">代码10-8　变分自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">40 h1=tf.nn.relu(tf.add(tf.matmul(x, weights['w1']), weights['b1']))
41 z_mean = tf.add(tf.matmul(h1, weights['mean_w1']), weights['mean_b1'])
42 z_log_sigma_sq = tf.add(tf.matmul(h1, weights['log_sigma_w1']), 
weights['log_sigma_b1'])
43 
44  # 高斯分布样本
45 eps = tf.random_normal(tf.stack([tf.shape(h1)[0], n_hidden_2]), 0, 1, 
dtype = tf.float32)
46 z =tf.add(z_mean, tf.multiply(tf.sqrt(tf.exp(z_log_sigma_sq)), eps))
47 h2=tf.nn.relu( tf.matmul(z, weights['w2'])+ weights['b2'])
48 reconstruction = tf.matmul(h2, weights['w3'])+ weights['b3']
49 
50 h2out=tf.nn.relu( tf.matmul(zinput, weights['w2'])+ weights['b2'])
51 reconstructionout = tf.matmul(h2out, weights['w3'])+ weights['b3']</pre>
<hr class="calibre6"/>
<p class="ziti3">得到了符合原数据集上的一个具体点z之后，就可以通过神经网络这个点z还原成原始数据reconstruction了。解码部分和前面一样，参照编码的网络逐层还原回去即可。</p>
<p class="ziti3">h2out和reconstructionout两个节点不属于训练中的结构，是为了生成指定数据时用的。</p>
<p class="ziti4">
<span class="yanse">4．构建模型的反向传播</span>
</p>
<p class="ziti3">这一步和前面一样，需要定义损失函数的节点和优化算法的OP，代码如下。</p>
<p class="ziti3">代码10-8　变分自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">52 # 计算重建loss
53 reconstr_loss = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(reconstruction,
 x), 2.0))
54 latent_loss = -0.5 * tf.reduce_sum(1 + z_log_sigma_sq
55                                    - tf.square(z_mean)
56                                    - tf.exp(z_log_sigma_sq), 1)
57 cost = tf.reduce_mean(reconstr_loss + latent_loss)
58 
59 optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize
(cost)</pre>
<hr class="calibre6"/>
<p class="ziti3">上面代码描述了网络的两个优化方向：</p>
<p class="ziti4">·一个是比较生成的数据分布与标准高斯分布的距离，这里使用KL离散度的公式（见latent_loss）。</p>
<p class="ziti4">·另一个是计算生成数据与原始数据间的损失，这里用的是平方差，也可以用交叉熵。</p>
<p class="ziti3">最后将两种损失值放在一起，通过Adam的随机梯度下降算法实现在训练中的优化参数。</p>
<p class="ziti4">
<span class="yanse">5．设置参数，进行训练</span>
</p>
<p class="ziti3">这一步与前面类似，设置训练参数，迭代50次，在session中每次循环取指定批次数据进行训练。</p>
<p class="ziti3">代码10-8　变分自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">60 training_epochs = 50
61 batch_size = 128
62 display_step = 3
63 
64 with tf.Session() as sess:
65     sess.run(tf.global_variables_initializer())
66     
67     for epoch in range(training_epochs):
68         avg_cost = 0.
69         total_batch = int(mnist.train.num_examples/batch_size)
70 
71         # 遍历全部数据集
72         for i in range(total_batch):
73             batch_xs, batch_ys = mnist.train.next_batch(batch_size)#取数据
74             
75             # 输入数据，运行优化器
76             _,c = sess.run([optimizer,cost], feed_dict={x: batch_xs})
77             
78         # 显示训练中的详细信息
79         if epoch % display_step == 0:
80             print("Epoch:", '%04d' % (epoch + 1), "cost=", "{:.9f}".
            format(c))
81 
82     print("完成!")
83     
84     # 测试
85     print ("Result:", cost.eval({x: mnist.test.images}))</pre>
<hr class="calibre6"/>
<p class="ziti3">可视化部分这里不再详述，读者可以参考本书的配套代码，最终程序运行的结果输出如下，输出图片如图10-18所示。</p>
<hr class="calibre6"/>
<pre class="ziti5">Epoch: 0001 cost= 2766.966308594
Epoch: 0004 cost= 2503.895507812
Epoch: 0007 cost= 2177.547363281
Epoch: 0010 cost= 2221.667724609
Epoch: 0013 cost= 2110.643798828
Epoch: 0016 cost= 2103.255859375
Epoch: 0019 cost= 2258.502685547
Epoch: 0022 cost= 2231.131347656
Epoch: 0025 cost= 2092.596191406
Epoch: 0028 cost= 2018.563964844
Epoch: 0031 cost= 1993.950439453
Epoch: 0034 cost= 2091.635253906
Epoch: 0037 cost= 1992.461059570
Epoch: 0040 cost= 2018.574462891
Epoch: 0043 cost= 1992.727661133
Epoch: 0046 cost= 2056.166503906
Epoch: 0049 cost= 1939.133544922
完成!
Result: 156414.0</pre>
<hr class="calibre6"/>
<div class="pic"><img alt="" src="Image00218.jpg" class="calibre4"/>
</div>
<p class="middle-img">图10-18　变分自编码结果</p>
<p class="ziti3">图10-18中，第一行代表原始的样本图片，第二行代表变分自编码重建后生成的图片。可以看到生成的数字中不再一味单纯地学习形状，而是通过数据分布的方式学习规则，对原有图片具有更清晰的修正功能。</p>
<p class="ziti3">仿照前面的可视化代码，将均值和方差代表的二维数据在直角坐标系中展现如下，如图10-19所示。</p>
<div class="pic"><img alt="" src="Image00219.jpg" class="calibre4"/>
</div>
<p class="middle-img">图10-19　变分自编码二维可视化</p>
<p class="ziti3">从图10-19中可以看出，MNIST数据集中同一类样本的特征分布还是比较集中的，说明变分自解码也具有降维功能，也可以用它进行分类任务的数据降维预处理。</p>
<p class="ziti4">
<span class="yanse">6．高斯分布取样，生成模拟数据</span>
</p>
<p class="ziti3">为了进一步证实模型学到了数据分布的情况，这次在高斯分布抽样中取一些点，将其映射到模型中的z，然后通过解码部分还原成真实图片看看效果，代码如下。</p>
<p class="ziti4">
<span class="yanse"><img alt="" class="formula-2em" src="Image00014.jpg"/>
 注意：</span>
 代码中norm.ppf函数的作用是从按照百分比由大到小排列后的标准高斯分布中取值。np.linspace（0.05，0.95，n）的意思是，将整个高斯分布数据集从大到小排列，取出前0.05%到0.95%区间，并且分成n份，每份对应的点的具体数值。</p>
<p class="ziti3">norm代表标准高斯分布，ppf代表累积分布函数的反函数。累积分布的意思是，在一个结合里所有小于a的值出现的概率的和。例如，x=ppf（0.05）就代表在集合里有个x，集合中每个小于x的数在集合里出现的概率的总和等于0.05。</p>
<p class="ziti3">代码10-8　变分自编码（续）</p>
<hr class="calibre6"/>
<pre class="ziti5">86     n = 15  # 15×15 的figure 
87     digit_size = 28
88     figure = np.zeros((digit_size * n, digit_size * n))
89     grid_x = norm.ppf(np.linspace(0.05, 0.95, n))
90     grid_y = norm.ppf(np.linspace(0.05, 0.95, n))
91     
92     for i, yi in enumerate(grid_x):
93         for j, xi in enumerate(grid_y):
94             z_sample = np.array([[xi, yi]])
95             x_decoded = sess.run(reconstructionout,feed_dict={zinput:z_
            sample})
96             
97             digit = x_decoded[0].reshape(digit_size, digit_size)
98             figure[i * digit_size: (i + 1) * digit_size,
99                    j * digit_size: (j + 1) * digit_size] = digit
100     
101     plt.figure(figsize=(10, 10))
102     plt.imshow(figure, cmap='Greys_r')
103     plt.show()  </pre>
<hr class="calibre6"/>
<p class="ziti3">运行以上代码，生成图片如图10-20所示。</p>
<div class="pic"><img alt="" src="Image00220.jpg" class="calibre4"/>
</div>
<p class="middle-img">图10-20　变分自编码生成模拟数据</p>
<p class="ziti3">可以看到，在神经网络的世界里，从左下角到右上角显示了网络是按照图片的形状变化而排列的，并不像人类一样，把数字按照1到9的顺序排列，因为机器学的只是图片，而人类对数字的理解更多的是其代表的意思。</p>
<h4 class="p3">10.9.3　练习题</h4>
<p class="ziti3">读者可以自己试试在初始化时将所有的w设为0和设为truncated_normal，不指定stddev的效果，想想为什么？</p>
<div class="calibre1">本书由「<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a>」整理，<a href="https://epubw.com" class="pcalibre calibre2">ePUBw.COM</a> 提供最新最全的优质电子书下载！！！</div></body>
</html>
